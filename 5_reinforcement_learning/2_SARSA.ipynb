{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef6e1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32aca74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSize = 8\n",
    "Goal = (7, 7)\n",
    "Traps = [(0, 4), (2, 2), (4, 1), (5, 3), (6, 6)]\n",
    "ActionsList = ['UP', 'DOWN', 'LEFT', 'RIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3098b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((GridSize, GridSize, 4))\n",
    "\n",
    "Alpha = 0.5\n",
    "Gamma = 0.9\n",
    "Epsilon = 0.2\n",
    "Episodes = 80\n",
    "Delay = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30f3a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 3: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 4: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 5: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 6: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 7: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 8: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 9: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 10: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 11: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 12: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 13: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 14: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 15: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 16: State (5, 5), Action UP, Reward -1, Next (4, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 17: State (4, 5), Action LEFT, Reward -1, Next (4, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 18: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 19: State (5, 4), Action UP, Reward -1, Next (4, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 20: State (4, 4), Action UP, Reward -1, Next (3, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 21: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 22: State (3, 5), Action LEFT, Reward -1, Next (3, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 23: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 25: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 26: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 27: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 28: State (0, 3), Action RIGHT, Reward -10, Next (0, 4), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 2\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 5: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 6: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 7: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 8: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 10: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 11: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 12: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 13: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 14: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 15: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 16: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 17: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 18: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 19: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 20: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 21: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 22: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 23: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 25: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 26: State (3, 2), Action UP, Reward -10, Next (2, 2), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 3\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -1.21 → -1.44\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 6: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 7: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 8: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 9: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 10: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 11: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 12: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 13: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 14: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 15: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -0.72 → -1.20\n",
      "Step 16: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 17: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 18: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 19: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 20: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 21: State (1, 2), Action DOWN, Reward -10, Next (2, 2), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 4\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -1.10 → -1.39\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 4: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 5: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 6: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 7: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 8: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploring, Q -0.50 → -3.00\n",
      "Step 9: State (3, 2), Action UP, Reward -10, Next (2, 2), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 5\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.10 → -1.38\n",
      "Step 2: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -0.72 → -1.41\n",
      "Step 3: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -1.21 → -1.76\n",
      "Step 4: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -1.44 → -1.84\n",
      "Step 5: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.38 → -1.53\n",
      "Step 6: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 7: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -1.21 → -1.44\n",
      "Step 8: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 10: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q 0.00 → -0.83\n",
      "Step 11: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -0.72 → -1.20\n",
      "Step 12: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 13: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 14: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 15: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -0.50 → -1.38\n",
      "Step 16: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -1.41 → -1.83\n",
      "Step 17: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -1.39 → -1.63\n",
      "Step 18: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploring, Q -0.97 → -1.31\n",
      "Step 19: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -0.72 → -1.20\n",
      "Step 20: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 21: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -1.21 → -1.60\n",
      "Step 22: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -1.10 → -1.27\n",
      "Step 23: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 24: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -0.97 → -1.21\n",
      "Step 25: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 26: State (2, 1), Action RIGHT, Reward -10, Next (2, 2), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 6\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.53 → -1.76\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -1.10 → -1.39\n",
      "Step 3: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 4: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -0.72 → -1.20\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 6: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -0.72 → -0.86\n",
      "Step 7: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 8: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 10: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 11: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 12: State (1, 4), Action UP, Reward -10, Next (0, 4), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 7\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploring, Q -1.76 → -1.87\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -1.10 → -1.27\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 4: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q 0.00 → -0.84\n",
      "Step 5: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 6: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -1.21 → -1.44\n",
      "Step 7: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 8: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 9: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 10: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -0.50 → -1.13\n",
      "Step 11: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -0.84 → -1.36\n",
      "Step 12: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 13: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 14: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 15: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 16: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 17: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 18: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 19: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 20: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q -0.50 → -1.12\n",
      "Step 21: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -0.83 → -1.41\n",
      "Step 22: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -1.10 → -1.49\n",
      "Step 23: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -0.97 → -1.48\n",
      "Step 24: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -1.10 → -1.49\n",
      "Step 25: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 26: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -1.43 → -1.65\n",
      "Step 27: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 28: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 29: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 30: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 31: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploring, Q -0.50 → -1.09\n",
      "Step 32: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 33: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploring, Q -0.72 → -1.09\n",
      "Step 34: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 35: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 36: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 37: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 38: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 39: State (3, 2), Action LEFT, Reward -1, Next (3, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 40: State (3, 1), Action DOWN, Reward -10, Next (4, 1), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 8\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -1.63 → -1.86\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -1.20 → -1.94\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -1.86 → -2.00\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -1.27 → -1.48\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 6: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 7: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 8: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -0.50 → -1.23\n",
      "Step 9: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -1.08 → -1.63\n",
      "Step 10: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -1.31 → -1.70\n",
      "Step 11: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -1.20 → -1.67\n",
      "Step 12: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -1.27 → -1.73\n",
      "Step 13: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -1.32 → -1.66\n",
      "Step 14: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q -1.10 → -1.55\n",
      "Step 15: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploring, Q -1.12 → -1.69\n",
      "Step 16: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploring, Q -1.41 → -1.96\n",
      "Step 17: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -1.67 → -1.96\n",
      "Step 18: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -1.39 → -1.73\n",
      "Step 19: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -1.20 → -1.97\n",
      "Step 20: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -1.94 → -2.26\n",
      "Step 21: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -1.76 → -2.17\n",
      "Step 22: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -2.17 → -2.41\n",
      "Step 23: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -1.84 → -2.25\n",
      "Step 24: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -2.25 → -2.47\n",
      "Step 25: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.87 → -2.22\n",
      "Step 26: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -1.73 → -1.91\n",
      "Step 27: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploring, Q -1.20 → -1.44\n",
      "Step 28: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 29: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -0.72 → -1.40\n",
      "Step 30: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -1.20 → -1.60\n",
      "Step 31: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -1.10 → -1.54\n",
      "Step 32: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -1.09 → -1.69\n",
      "Step 33: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -1.44 → -1.76\n",
      "Step 34: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -1.20 → -1.43\n",
      "Step 35: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -0.72 → -1.09\n",
      "Step 36: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 37: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 38: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 39: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 40: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 41: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 42: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 43: State (4, 0), Action RIGHT, Reward -10, Next (4, 1), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 9\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -2.00 → -2.16\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -1.48 → -1.93\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -1.54 → -1.91\n",
      "Step 4: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -1.43 → -1.70\n",
      "Step 5: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -1.09 → -1.27\n",
      "Step 6: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 7: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 8: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 9: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -0.50 → -1.14\n",
      "Step 10: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -0.86 → -1.50\n",
      "Step 11: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -1.27 → -1.63\n",
      "Step 12: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -1.10 → -1.39\n",
      "Step 13: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 14: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 15: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 16: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 17: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 18: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 19: State (5, 1), Action UP, Reward -10, Next (4, 1), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 10\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -2.16 → -2.30\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -1.60 → -2.02\n",
      "Step 3: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -2.02 → -2.27\n",
      "Step 4: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -1.70 → -2.02\n",
      "Step 5: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -1.49 → -1.91\n",
      "Step 6: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -1.48 → -1.86\n",
      "Step 7: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.38 → -1.84\n",
      "Step 8: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -1.44 → -2.04\n",
      "Step 9: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -1.83 → -2.41\n",
      "Step 10: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -2.22 → -2.39\n",
      "Step 11: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -1.73 → -2.02\n",
      "Step 12: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -1.44 → -1.89\n",
      "Step 13: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -1.49 → -1.79\n",
      "Step 14: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -1.21 → -1.54\n",
      "Step 15: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -0.97 → -0.99\n",
      "Step 16: State (2, 3), Action LEFT, Reward -10, Next (2, 2), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 11\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -2.30 → -2.52\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -1.93 → -2.01\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -1.20 → -1.66\n",
      "Step 4: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -1.23 → -1.98\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -1.91 → -2.17\n",
      "Step 6: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -1.60 → -1.84\n",
      "Step 7: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -1.21 → -1.65\n",
      "Step 8: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -1.65 → -2.07\n",
      "Step 9: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -1.66 → -1.92\n",
      "Step 10: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -1.32 → -1.76\n",
      "Step 11: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -1.76 → -2.06\n",
      "Step 12: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -1.50 → -1.88\n",
      "Step 13: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -1.40 → -1.96\n",
      "Step 14: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -1.69 → -2.14\n",
      "Step 15: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -1.76 → -2.15\n",
      "Step 16: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -1.70 → -2.08\n",
      "Step 17: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -1.63 → -2.16\n",
      "Step 18: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -1.88 → -2.41\n",
      "Step 19: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q -2.16 → -2.21\n",
      "Step 20: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -1.39 → -1.53\n",
      "Step 21: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 22: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 23: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 25: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 26: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 27: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 28: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 29: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 30: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 31: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 32: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 33: State (6, 4), Action UP, Reward -1, Next (5, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 34: State (5, 4), Action DOWN, Reward -1, Next (6, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 35: State (6, 4), Action LEFT, Reward -1, Next (6, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 36: State (6, 3), Action UP, Reward -10, Next (5, 3), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 12\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -2.39 → -2.55\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -1.91 → -2.31\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -1.91 → -2.16\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -1.55 → -1.72\n",
      "Step 5: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -0.99 → -1.22\n",
      "Step 6: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 7: State (3, 3), Action UP, Reward -1, Next (2, 3), Mode Exploring, Q 0.00 → -0.83\n",
      "Step 8: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploiting, Q -0.72 → -1.37\n",
      "Step 9: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -1.13 → -1.67\n",
      "Step 10: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -1.36 → -1.92\n",
      "Step 11: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -1.66 → -2.10\n",
      "Step 12: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -1.72 → -1.90\n",
      "Step 13: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.20 → -1.10\n",
      "Step 14: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 15: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 16: State (0, 5), Action LEFT, Reward -10, Next (0, 4), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 13\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -2.41 → -2.79\n",
      "Step 2: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -2.79 → -3.03\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -2.52 → -2.66\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -2.01 → -2.24\n",
      "Step 5: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -1.63 → -2.22\n",
      "Step 6: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -2.02 → -2.39\n",
      "Step 7: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -1.96 → -2.39\n",
      "Step 8: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -2.02 → -2.31\n",
      "Step 9: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -1.79 → -2.09\n",
      "Step 10: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -1.54 → -1.77\n",
      "Step 11: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.10 → -1.54\n",
      "Step 12: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploring, Q -1.09 → -1.27\n",
      "Step 13: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 14: State (2, 5), Action LEFT, Reward -1, Next (2, 4), Mode Exploiting, Q 0.00 → -0.84\n",
      "Step 15: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 16: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 17: State (1, 5), Action LEFT, Reward -1, Next (1, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 18: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 19: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 20: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 21: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 22: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 23: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 25: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 26: State (2, 7), Action UP, Reward -1, Next (1, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 27: State (1, 7), Action LEFT, Reward -1, Next (1, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 28: State (1, 6), Action LEFT, Reward -1, Next (1, 5), Mode Exploiting, Q 0.00 → -0.83\n",
      "Step 29: State (1, 5), Action LEFT, Reward -1, Next (1, 4), Mode Exploring, Q -0.72 → -1.20\n",
      "Step 30: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 31: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 32: State (0, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q 0.00 → -2.75\n",
      "Step 33: State (0, 5), Action LEFT, Reward -10, Next (0, 4), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 14\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -2.47 → -2.88\n",
      "Step 2: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploring, Q -2.55 → -2.70\n",
      "Step 3: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -2.04 → -2.56\n",
      "Step 4: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -2.31 → -2.54\n",
      "Step 5: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -1.97 → -2.49\n",
      "Step 6: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -2.24 → -2.48\n",
      "Step 7: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -1.92 → -2.55\n",
      "Step 8: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -2.41 → -2.59\n",
      "Step 9: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -1.96 → -2.31\n",
      "Step 10: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -1.84 → -2.35\n",
      "Step 11: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -2.07 → -2.51\n",
      "Step 12: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -2.17 → -2.52\n",
      "Step 13: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -2.08 → -2.53\n",
      "Step 14: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.21 → -2.29\n",
      "Step 15: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -1.53 → -1.76\n",
      "Step 16: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -1.10 → -1.27\n",
      "Step 17: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploring, Q -0.50 → -1.25\n",
      "Step 18: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -1.10 → -1.62\n",
      "Step 19: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploring, Q -1.27 → -1.36\n",
      "Step 20: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 21: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 22: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 23: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 25: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q 0.00 → -0.84\n",
      "Step 26: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 27: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 28: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 29: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -1.21 → -1.44\n",
      "Step 30: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 31: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 32: State (5, 2), Action LEFT, Reward -1, Next (5, 1), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 33: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 34: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 35: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 36: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 37: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 38: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 39: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 40: State (5, 2), Action RIGHT, Reward -10, Next (5, 3), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 15\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -2.66 → -2.85\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -2.26 → -2.84\n",
      "Step 3: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -2.70 → -2.89\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -2.31 → -2.49\n",
      "Step 5: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -1.84 → -2.51\n",
      "Step 6: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -2.41 → -2.99\n",
      "Step 7: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -2.85 → -3.04\n",
      "Step 8: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploring, Q -2.48 → -2.74\n",
      "Step 9: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -2.22 → -2.89\n",
      "Step 10: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -2.84 → -3.22\n",
      "Step 11: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -2.88 → -3.24\n",
      "Step 12: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -3.24 → -3.42\n",
      "Step 13: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -2.89 → -3.06\n",
      "Step 14: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -2.49 → -2.68\n",
      "Step 15: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -2.09 → -2.29\n",
      "Step 16: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -1.65 → -2.07\n",
      "Step 17: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.07 → -2.33\n",
      "Step 18: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploring, Q -1.77 → -1.93\n",
      "Step 19: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.22 → -1.45\n",
      "Step 20: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 21: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 22: State (4, 3), Action UP, Reward -1, Next (3, 3), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 23: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 24: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 25: State (4, 4), Action LEFT, Reward -1, Next (4, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 26: State (4, 3), Action DOWN, Reward -10, Next (5, 3), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 16\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -3.03 → -3.38\n",
      "Step 2: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -3.38 → -3.56\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.04 → -3.47\n",
      "Step 4: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -3.22 → -3.49\n",
      "Step 5: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.06 → -3.18\n",
      "Step 6: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -2.54 → -2.74\n",
      "Step 7: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -2.15 → -3.82\n",
      "Step 8: State (2, 1), Action RIGHT, Reward -10, Next (2, 2), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 17\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -3.42 → -3.64\n",
      "Step 2: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.18 → -3.24\n",
      "Step 3: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -2.56 → -2.94\n",
      "Step 4: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -2.94 → -3.18\n",
      "Step 5: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -2.68 → -2.79\n",
      "Step 6: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q -2.10 → -2.39\n",
      "Step 7: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -1.86 → -2.28\n",
      "Step 8: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -1.89 → -2.30\n",
      "Step 9: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -2.30 → -2.68\n",
      "Step 10: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -2.29 → -2.51\n",
      "Step 11: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -1.92 → -2.54\n",
      "Step 12: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -2.39 → -2.55\n",
      "Step 13: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -1.90 → -2.10\n",
      "Step 14: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.45 → -1.56\n",
      "Step 15: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 16: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -0.72 → -0.86\n",
      "Step 17: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 18: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 19: State (4, 3), Action LEFT, Reward -1, Next (4, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 20: State (4, 2), Action LEFT, Reward -10, Next (4, 1), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 18\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.24 → -3.38\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -2.79 → -3.02\n",
      "Step 3: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -2.51 → -3.11\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -3.02 → -3.14\n",
      "Step 5: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -2.51 → -2.62\n",
      "Step 6: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -1.93 → -2.16\n",
      "Step 7: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.54 → -1.76\n",
      "Step 8: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploiting, Q -1.09 → -1.80\n",
      "Step 9: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q -1.67 → -2.31\n",
      "Step 10: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -2.16 → -2.28\n",
      "Step 11: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.56 → -1.67\n",
      "Step 12: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -0.88 → -1.16\n",
      "Step 13: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 14: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 15: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 16: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 17: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 18: State (4, 5), Action UP, Reward -1, Next (3, 5), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 19: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 20: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 21: State (4, 6), Action RIGHT, Reward -1, Next (4, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 22: State (4, 7), Action UP, Reward -1, Next (3, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 23: State (3, 7), Action LEFT, Reward -1, Next (3, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 24: State (3, 6), Action UP, Reward -1, Next (2, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 25: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 26: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 27: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 28: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 29: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 30: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 31: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 32: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 33: State (3, 7), Action UP, Reward -1, Next (2, 7), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 34: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 35: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 36: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 37: State (5, 7), Action LEFT, Reward -1, Next (5, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 38: State (5, 6), Action UP, Reward -1, Next (4, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 39: State (4, 6), Action UP, Reward -1, Next (3, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 40: State (3, 6), Action DOWN, Reward -1, Next (4, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 41: State (4, 6), Action DOWN, Reward -1, Next (5, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 42: State (5, 6), Action DOWN, Reward -10, Next (6, 6), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 19\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -3.56 → -3.80\n",
      "Step 2: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.38 → -3.42\n",
      "Step 3: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -2.74 → -2.84\n",
      "Step 4: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -2.16 → -2.46\n",
      "Step 5: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -1.96 → -2.55\n",
      "Step 6: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -2.39 → -2.97\n",
      "Step 7: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -2.84 → -3.03\n",
      "Step 8: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -2.46 → -2.68\n",
      "Step 9: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.10 → -2.30\n",
      "Step 10: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.67 → -1.86\n",
      "Step 11: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploring, Q -1.16 → -1.42\n",
      "Step 12: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 13: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 14: State (4, 4), Action UP, Reward -1, Next (3, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 15: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 16: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 17: State (3, 6), Action LEFT, Reward -1, Next (3, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 18: State (3, 5), Action UP, Reward -1, Next (2, 5), Mode Exploiting, Q 0.00 → -0.84\n",
      "Step 19: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 20: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 21: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 22: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 23: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 24: State (3, 7), Action LEFT, Reward -1, Next (3, 6), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 25: State (3, 6), Action UP, Reward -1, Next (2, 6), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 26: State (2, 6), Action LEFT, Reward -1, Next (2, 5), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 27: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 28: State (3, 5), Action LEFT, Reward -1, Next (3, 4), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 29: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploiting, Q -0.72 → -1.20\n",
      "Step 30: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 31: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 32: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q 0.00 → -2.75\n",
      "Step 33: State (4, 3), Action DOWN, Reward -10, Next (5, 3), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 20\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.42 → -3.55\n",
      "Step 2: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -2.99 → -3.55\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.47 → -3.26\n",
      "Step 4: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -2.27 → -2.66\n",
      "Step 5: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -2.66 → -3.03\n",
      "Step 6: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -3.03 → -3.09\n",
      "Step 7: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -2.39 → -2.82\n",
      "Step 8: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -2.49 → -2.98\n",
      "Step 9: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -2.74 → -3.00\n",
      "Step 10: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -2.51 → -2.89\n",
      "Step 11: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -2.89 → -3.08\n",
      "Step 12: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -2.52 → -2.72\n",
      "Step 13: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -2.14 → -2.77\n",
      "Step 14: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -2.68 → -2.86\n",
      "Step 15: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -2.28 → -2.79\n",
      "Step 16: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -2.55 → -2.81\n",
      "Step 17: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.30 → -2.41\n",
      "Step 18: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploring, Q -1.69 → -2.43\n",
      "Step 19: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.41 → -2.50\n",
      "Step 20: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.76 → -1.87\n",
      "Step 21: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -1.10 → -1.27\n",
      "Step 22: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 23: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 24: State (0, 6), Action LEFT, Reward -1, Next (0, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 25: State (0, 5), Action DOWN, Reward -1, Next (1, 5), Mode Exploiting, Q 0.00 → -0.94\n",
      "Step 26: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploring, Q -0.97 → -1.21\n",
      "Step 27: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 28: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 29: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 30: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 31: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 32: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 33: State (0, 7), Action LEFT, Reward -1, Next (0, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 34: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 35: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 36: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 37: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploring, Q -0.97 → -1.21\n",
      "Step 38: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 39: State (2, 7), Action LEFT, Reward -1, Next (2, 6), Mode Exploiting, Q 0.00 → -0.94\n",
      "Step 40: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploring, Q -0.97 → -1.32\n",
      "Step 41: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 42: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 43: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 44: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploiting, Q -0.50 → -1.12\n",
      "Step 45: State (1, 6), Action LEFT, Reward -1, Next (1, 5), Mode Exploiting, Q -0.83 → -1.25\n",
      "Step 46: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 47: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 48: State (0, 6), Action LEFT, Reward -1, Next (0, 5), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 49: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploiting, Q -0.72 → -1.19\n",
      "Step 50: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -0.72 → -1.30\n",
      "Step 51: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploring, Q -0.97 → -1.21\n",
      "Step 52: State (1, 7), Action LEFT, Reward -1, Next (1, 6), Mode Exploiting, Q -0.50 → -1.19\n",
      "Step 53: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 54: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 55: State (3, 6), Action DOWN, Reward -1, Next (4, 6), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 56: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 57: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 58: State (5, 5), Action LEFT, Reward -1, Next (5, 4), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 59: State (5, 4), Action LEFT, Reward -10, Next (5, 3), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 21\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.26 → -3.40\n",
      "Step 2: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -2.82 → -3.20\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -2.86 → -3.06\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q -2.50 → -2.59\n",
      "Step 5: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.86 → -1.97\n",
      "Step 6: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -1.20 → -1.44\n",
      "Step 7: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploiting, Q -0.75 → -1.49\n",
      "Step 8: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploiting, Q -1.37 → -2.03\n",
      "Step 9: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.87 → -2.01\n",
      "Step 10: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -1.27 → -1.52\n",
      "Step 11: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -0.86 → -1.47\n",
      "Step 12: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploring, Q -1.20 → -1.47\n",
      "Step 13: State (3, 3), Action UP, Reward -1, Next (2, 3), Mode Exploiting, Q -0.83 → -1.55\n",
      "Step 14: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -1.42 → -1.60\n",
      "Step 15: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -0.88 → -1.16\n",
      "Step 16: State (4, 3), Action UP, Reward -1, Next (3, 3), Mode Exploiting, Q -0.50 → -1.19\n",
      "Step 17: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 18: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploiting, Q -0.75 → -1.31\n",
      "Step 19: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q -0.97 → -1.67\n",
      "Step 20: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploring, Q -1.52 → -2.01\n",
      "Step 21: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploring, Q -1.67 → -1.91\n",
      "Step 22: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -1.27 → -1.48\n",
      "Step 23: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 24: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 25: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 26: State (2, 7), Action UP, Reward -1, Next (1, 7), Mode Exploiting, Q -0.50 → -1.28\n",
      "Step 27: State (1, 7), Action LEFT, Reward -1, Next (1, 6), Mode Exploring, Q -1.19 → -1.53\n",
      "Step 28: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 29: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 30: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 31: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q -0.97 → -1.32\n",
      "Step 32: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 33: State (3, 7), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 34: State (3, 7), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 35: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 36: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 37: State (5, 7), Action UP, Reward -1, Next (4, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 38: State (4, 7), Action LEFT, Reward -1, Next (4, 6), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 39: State (4, 6), Action UP, Reward -1, Next (3, 6), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 40: State (3, 6), Action LEFT, Reward -1, Next (3, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 41: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 42: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q -0.72 → -1.19\n",
      "Step 43: State (3, 7), Action UP, Reward -1, Next (2, 7), Mode Exploiting, Q -0.72 → -1.26\n",
      "Step 44: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q -0.88 → -1.38\n",
      "Step 45: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q -0.97 → -1.31\n",
      "Step 46: State (4, 7), Action LEFT, Reward -1, Next (4, 6), Mode Exploring, Q -0.72 → -1.09\n",
      "Step 47: State (4, 6), Action DOWN, Reward -1, Next (5, 6), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 48: State (5, 6), Action LEFT, Reward -1, Next (5, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 49: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 50: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 51: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 52: State (6, 7), Action RIGHT, Reward -1, Next (6, 7), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 53: State (6, 7), Action RIGHT, Reward -1, Next (6, 7), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 54: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploring, Q 0.00 → 50.00\n",
      "\n",
      "Episode 22\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -3.80 → -3.93\n",
      "Step 2: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.40 → -3.55\n",
      "Step 3: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.00 → -3.39\n",
      "Step 4: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -3.08 → -3.19\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -2.55 → -2.57\n",
      "Step 6: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -1.76 → -1.89\n",
      "Step 7: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -1.14 → -1.92\n",
      "Step 8: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -1.89 → -2.06\n",
      "Step 9: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -1.36 → -1.74\n",
      "Step 10: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploring, Q -1.25 → -1.85\n",
      "Step 11: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -1.62 → -2.04\n",
      "Step 12: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -2.04 → -2.30\n",
      "Step 13: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -1.74 → -2.02\n",
      "Step 14: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -1.44 → -1.62\n",
      "Step 15: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -0.88 → -1.31\n",
      "Step 16: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -0.84 → -1.41\n",
      "Step 17: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -1.10 → -1.27\n",
      "Step 18: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 19: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 20: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 21: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 22: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 23: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 24: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 25: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 26: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 27: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 28: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 29: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 30: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 31: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 32: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 33: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 34: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 35: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploring, Q -0.97 → -0.99\n",
      "Step 36: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 37: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 38: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 39: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 40: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -0.75 → -1.31\n",
      "Step 41: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploring, Q -0.97 → -1.43\n",
      "Step 42: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 43: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploring, Q -0.97 → -1.32\n",
      "Step 44: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 45: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 46: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 47: State (7, 3), Action LEFT, Reward -1, Next (7, 2), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 48: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 49: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 50: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 51: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 52: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 53: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 54: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 55: State (7, 3), Action UP, Reward -1, Next (6, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 56: State (6, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 57: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 58: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 59: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 60: State (7, 4), Action LEFT, Reward -1, Next (7, 3), Mode Exploring, Q 0.00 → -0.72\n",
      "Step 61: State (7, 3), Action UP, Reward -1, Next (6, 3), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 62: State (6, 3), Action LEFT, Reward -1, Next (6, 2), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 63: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 64: State (6, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 65: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploring, Q -0.75 → -1.10\n",
      "Step 66: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 67: State (7, 4), Action LEFT, Reward -1, Next (7, 3), Mode Exploring, Q -0.72 → -1.19\n",
      "Step 68: State (7, 3), Action LEFT, Reward -1, Next (7, 2), Mode Exploiting, Q -0.72 → -1.31\n",
      "Step 69: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploring, Q -0.99 → -1.32\n",
      "Step 70: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploiting, Q -0.72 → -1.20\n",
      "Step 71: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 72: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 73: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploiting, Q -0.72 → -1.19\n",
      "Step 74: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -0.72 → -1.35\n",
      "Step 75: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploiting, Q -1.09 → -1.62\n",
      "Step 76: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -1.27 → -1.63\n",
      "Step 77: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -1.10 → -1.39\n",
      "Step 78: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -0.75 → -1.31\n",
      "Step 79: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 80: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 81: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -0.75 → -1.31\n",
      "Step 82: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 83: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 84: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 85: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 86: State (3, 2), Action LEFT, Reward -1, Next (3, 1), Mode Exploiting, Q -0.50 → -1.79\n",
      "Step 87: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploring, Q -2.31 → -2.71\n",
      "Step 88: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -2.35 → -2.83\n",
      "Step 89: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -2.57 → -2.67\n",
      "Step 90: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -1.98 → -2.69\n",
      "Step 91: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -2.67 → -3.00\n",
      "Step 92: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -2.59 → -2.83\n",
      "Step 93: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.29 → -2.57\n",
      "Step 94: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.06 → -2.45\n",
      "Step 95: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.45 → -2.65\n",
      "Step 96: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -2.06 → -3.78\n",
      "Step 97: State (4, 0), Action RIGHT, Reward -10, Next (4, 1), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 23\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.55 → -3.67\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -3.09 → -3.44\n",
      "Step 3: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -3.44 → -3.66\n",
      "Step 4: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -3.20 → -3.44\n",
      "Step 5: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -2.97 → -3.59\n",
      "Step 6: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -3.55 → -3.88\n",
      "Step 7: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.55 → -3.64\n",
      "Step 8: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -3.03 → -3.35\n",
      "Step 9: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -2.98 → -3.51\n",
      "Step 10: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.39 → -3.63\n",
      "Step 11: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -3.19 → -3.32\n",
      "Step 12: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -2.72 → -3.00\n",
      "Step 13: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -2.53 → -2.92\n",
      "Step 14: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.57 → -2.98\n",
      "Step 15: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.65 → -3.02\n",
      "Step 16: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -3.02 → -3.22\n",
      "Step 17: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -2.69 → -3.15\n",
      "Step 18: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -2.89 → -3.49\n",
      "Step 19: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -3.44 → -3.59\n",
      "Step 20: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.06 → -3.18\n",
      "Step 21: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -2.55 → -3.21\n",
      "Step 22: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.18 → -3.34\n",
      "Step 23: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploring, Q -2.79 → -3.08\n",
      "Step 24: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -2.62 → -2.84\n",
      "Step 25: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -2.28 → -2.53\n",
      "Step 26: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -1.97 → -2.13\n",
      "Step 27: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -1.44 → -1.88\n",
      "Step 28: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploring, Q -1.47 → -1.57\n",
      "Step 29: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 30: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 31: State (5, 4), Action RIGHT, Reward -1, Next (5, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 32: State (5, 5), Action DOWN, Reward -1, Next (6, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 33: State (6, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 34: State (7, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 35: State (7, 5), Action UP, Reward -1, Next (6, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 36: State (6, 5), Action UP, Reward -1, Next (5, 5), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 37: State (5, 5), Action UP, Reward -1, Next (4, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 38: State (4, 5), Action LEFT, Reward -1, Next (4, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 39: State (4, 4), Action LEFT, Reward -1, Next (4, 3), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 40: State (4, 3), Action LEFT, Reward -1, Next (4, 2), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 41: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 42: State (5, 2), Action LEFT, Reward -1, Next (5, 1), Mode Exploiting, Q -0.72 → -3.11\n",
      "Step 43: State (5, 1), Action UP, Reward -10, Next (4, 1), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 24\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.64 → -3.73\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.14 → -3.35\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -2.84 → -2.97\n",
      "Step 4: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.33 → -2.71\n",
      "Step 5: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.71 → -2.99\n",
      "Step 6: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -2.53 → -2.72\n",
      "Step 7: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -2.13 → -2.29\n",
      "Step 8: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -1.60 → -1.80\n",
      "Step 9: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -1.10 → -1.38\n",
      "Step 10: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -0.72 → -1.39\n",
      "Step 11: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -1.16 → -1.41\n",
      "Step 12: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -0.72 → -1.09\n",
      "Step 13: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 14: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 15: State (4, 6), Action RIGHT, Reward -1, Next (4, 7), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 16: State (4, 7), Action RIGHT, Reward -1, Next (4, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 17: State (4, 7), Action RIGHT, Reward -1, Next (4, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 18: State (4, 7), Action UP, Reward -1, Next (3, 7), Mode Exploiting, Q -0.50 → -1.19\n",
      "Step 19: State (3, 7), Action LEFT, Reward -1, Next (3, 6), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 20: State (3, 6), Action UP, Reward -1, Next (2, 6), Mode Exploiting, Q -0.75 → -1.47\n",
      "Step 21: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploring, Q -1.32 → -1.66\n",
      "Step 22: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -1.10 → -1.53\n",
      "Step 23: State (0, 6), Action LEFT, Reward -1, Next (0, 5), Mode Exploiting, Q -1.08 → -1.46\n",
      "Step 24: State (0, 5), Action DOWN, Reward -1, Next (1, 5), Mode Exploiting, Q -0.94 → -1.36\n",
      "Step 25: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -0.88 → -1.47\n",
      "Step 26: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploiting, Q -1.19 → -1.60\n",
      "Step 27: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploiting, Q -1.12 → -1.61\n",
      "Step 28: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -1.21 → -1.43\n",
      "Step 29: State (2, 6), Action LEFT, Reward -1, Next (2, 5), Mode Exploring, Q -0.72 → -1.30\n",
      "Step 30: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploring, Q -0.97 → -1.32\n",
      "Step 31: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 32: State (4, 5), Action UP, Reward -1, Next (3, 5), Mode Exploiting, Q -0.72 → -1.24\n",
      "Step 33: State (3, 5), Action UP, Reward -1, Next (2, 5), Mode Exploiting, Q -0.84 → -1.30\n",
      "Step 34: State (2, 5), Action LEFT, Reward -1, Next (2, 4), Mode Exploiting, Q -0.84 → -1.41\n",
      "Step 35: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -1.10 → -1.49\n",
      "Step 36: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 37: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q -0.97 → -1.58\n",
      "Step 38: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q -1.32 → -1.58\n",
      "Step 39: State (2, 7), Action LEFT, Reward -1, Next (2, 6), Mode Exploiting, Q -0.94 → -1.55\n",
      "Step 40: State (2, 6), Action LEFT, Reward -1, Next (2, 5), Mode Exploring, Q -1.30 → -1.65\n",
      "Step 41: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploiting, Q -1.10 → -1.59\n",
      "Step 42: State (1, 5), Action LEFT, Reward -1, Next (1, 4), Mode Exploring, Q -1.20 → -1.76\n",
      "Step 43: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -1.48 → -1.90\n",
      "Step 44: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q -1.47 → -1.85\n",
      "Step 45: State (0, 5), Action DOWN, Reward -1, Next (1, 5), Mode Exploiting, Q -1.36 → -2.01\n",
      "Step 46: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q -1.85 → -2.66\n",
      "Step 47: State (0, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q -2.75 → -3.11\n",
      "Step 48: State (0, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q -3.11 → -2.78\n",
      "Step 49: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploring, Q -1.60 → -2.02\n",
      "Step 50: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploring, Q -1.61 → -1.87\n",
      "Step 51: State (1, 6), Action LEFT, Reward -1, Next (1, 5), Mode Exploiting, Q -1.25 → -2.32\n",
      "Step 52: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploring, Q -2.66 → -2.74\n",
      "Step 53: State (0, 5), Action DOWN, Reward -1, Next (1, 5), Mode Exploiting, Q -2.01 → -2.00\n",
      "Step 54: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -1.10 → -1.65\n",
      "Step 55: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -1.32 → -1.65\n",
      "Step 56: State (3, 5), Action LEFT, Reward -1, Next (3, 4), Mode Exploiting, Q -1.08 → -1.53\n",
      "Step 57: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploring, Q -1.10 → -1.39\n",
      "Step 58: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 59: State (5, 4), Action UP, Reward -1, Next (4, 4), Mode Exploiting, Q -0.50 → -1.19\n",
      "Step 60: State (4, 4), Action UP, Reward -1, Next (3, 4), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 61: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploiting, Q -0.75 → -1.36\n",
      "Step 62: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploring, Q -1.08 → -1.38\n",
      "Step 63: State (3, 6), Action DOWN, Reward -1, Next (4, 6), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 64: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q -0.72 → -1.20\n",
      "Step 65: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 66: State (5, 5), Action DOWN, Reward -1, Next (6, 5), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 67: State (6, 5), Action LEFT, Reward -1, Next (6, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 68: State (6, 4), Action RIGHT, Reward -1, Next (6, 5), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 69: State (6, 5), Action RIGHT, Reward -10, Next (6, 6), Mode Exploiting, Q 0.00 → -5.00\n",
      "\n",
      "Episode 25\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -3.64 → -3.96\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -3.96 → -4.16\n",
      "Step 3: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploring, Q -3.73 → -3.80\n",
      "Step 4: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -3.18 → -3.52\n",
      "Step 5: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -3.52 → -3.76\n",
      "Step 6: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.35 → -3.57\n",
      "Step 7: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploring, Q -3.11 → -3.80\n",
      "Step 8: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -3.88 → -4.15\n",
      "Step 9: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploring, Q -3.80 → -3.91\n",
      "Step 10: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -3.35 → -3.68\n",
      "Step 11: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.34 → -3.34\n",
      "Step 12: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.59 → -2.70\n",
      "Step 13: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.01 → -2.31\n",
      "Step 14: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploiting, Q -1.80 → -2.43\n",
      "Step 15: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -2.29 → -2.45\n",
      "Step 16: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -1.80 → -1.99\n",
      "Step 17: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -1.32 → -1.75\n",
      "Step 18: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploiting, Q -1.31 → -1.83\n",
      "Step 19: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -1.49 → -1.88\n",
      "Step 20: State (2, 5), Action LEFT, Reward -1, Next (2, 4), Mode Exploiting, Q -1.41 → -1.88\n",
      "Step 21: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploring, Q -1.49 → -2.09\n",
      "Step 22: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -1.88 → -2.15\n",
      "Step 23: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -1.57 → -1.90\n",
      "Step 24: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploiting, Q -1.36 → -1.76\n",
      "Step 25: State (3, 5), Action UP, Reward -1, Next (2, 5), Mode Exploring, Q -1.30 → -1.86\n",
      "Step 26: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploring, Q -1.59 → -1.84\n",
      "Step 27: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploiting, Q -1.21 → -1.70\n",
      "Step 28: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -1.32 → -1.50\n",
      "Step 29: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 30: State (0, 7), Action LEFT, Reward -1, Next (0, 6), Mode Exploiting, Q -0.50 → -1.30\n",
      "Step 31: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -1.21 → -1.65\n",
      "Step 32: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -1.65 → -1.91\n",
      "Step 33: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -1.30 → -1.38\n",
      "Step 34: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 35: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 36: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -0.75 → -1.46\n",
      "Step 37: State (0, 7), Action LEFT, Reward -1, Next (0, 6), Mode Exploring, Q -1.30 → -1.77\n",
      "Step 38: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -1.38 → -1.73\n",
      "Step 39: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploiting, Q -1.21 → -1.60\n",
      "Step 40: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -1.10 → -1.65\n",
      "Step 41: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploring, Q -1.32 → -1.76\n",
      "Step 42: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploring, Q -1.76 → -2.04\n",
      "Step 43: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -1.46 → -1.89\n",
      "Step 44: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -1.89 → -2.16\n",
      "Step 45: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploiting, Q -1.60 → -1.80\n",
      "Step 46: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -1.10 → -1.63\n",
      "Step 47: State (2, 7), Action UP, Reward -1, Next (1, 7), Mode Exploiting, Q -1.28 → -1.69\n",
      "Step 48: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -1.21 → -1.65\n",
      "Step 49: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -1.65 → -2.02\n",
      "Step 50: State (1, 7), Action LEFT, Reward -1, Next (1, 6), Mode Exploiting, Q -1.53 → -1.91\n",
      "Step 51: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -1.43 → -1.65\n",
      "Step 52: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q -0.97 → -1.52\n",
      "Step 53: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploring, Q -1.19 → -1.66\n",
      "Step 54: State (3, 7), Action UP, Reward -1, Next (2, 7), Mode Exploring, Q -1.26 → -1.75\n",
      "Step 55: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q -1.38 → -1.63\n",
      "Step 56: State (3, 7), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 57: State (3, 7), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q -1.43 → -1.80\n",
      "Step 58: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q -1.31 → -1.60\n",
      "Step 59: State (4, 7), Action RIGHT, Reward -1, Next (4, 7), Mode Exploring, Q -0.97 → -1.32\n",
      "Step 60: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q -0.75 → -0.88\n",
      "Step 61: State (5, 7), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 62: State (5, 7), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 63: State (5, 7), Action UP, Reward -1, Next (4, 7), Mode Exploring, Q -0.50 → -1.14\n",
      "Step 64: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q -0.88 → -1.16\n",
      "Step 65: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q -0.50 → 21.75\n",
      "Step 66: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 50.00 → 75.00\n",
      "\n",
      "Episode 26\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.67 → -3.98\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -3.66 → -3.90\n",
      "Step 3: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -3.49 → -4.00\n",
      "Step 4: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.91 → -4.06\n",
      "Step 5: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.57 → -3.49\n",
      "Step 6: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -2.68 → -3.04\n",
      "Step 7: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.04 → -3.29\n",
      "Step 8: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -2.81 → -3.12\n",
      "Step 9: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.70 → -2.89\n",
      "Step 10: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.31 → -2.80\n",
      "Step 11: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -2.54 → -3.10\n",
      "Step 12: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -2.97 → -3.21\n",
      "Step 13: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -2.72 → -2.97\n",
      "Step 14: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -2.45 → -2.64\n",
      "Step 15: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploring, Q -2.03 → -2.55\n",
      "Step 16: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.31 → -2.51\n",
      "Step 17: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -1.90 → -2.22\n",
      "Step 18: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploring, Q -1.70 → -2.04\n",
      "Step 19: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploring, Q -1.53 → -1.92\n",
      "Step 20: State (0, 6), Action LEFT, Reward -1, Next (0, 5), Mode Exploiting, Q -1.46 → -4.61\n",
      "Step 21: State (0, 5), Action LEFT, Reward -10, Next (0, 4), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 27\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -3.93 → -4.23\n",
      "Step 2: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -4.23 → -4.49\n",
      "Step 3: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -4.16 → -4.45\n",
      "Step 4: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -4.45 → -4.74\n",
      "Step 5: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -4.49 → -4.53\n",
      "Step 6: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -3.98 → -4.11\n",
      "Step 7: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -3.59 → -3.80\n",
      "Step 8: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.34 → -3.47\n",
      "Step 9: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q -2.89 → -3.04\n",
      "Step 10: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q -2.43 → -3.08\n",
      "Step 11: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.04 → -3.15\n",
      "Step 12: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.51 → -2.66\n",
      "Step 13: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -2.01 → -2.35\n",
      "Step 14: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -1.88 → -2.18\n",
      "Step 15: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploring, Q -1.65 → -1.86\n",
      "Step 16: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -1.20 → -1.54\n",
      "Step 17: State (4, 5), Action LEFT, Reward -1, Next (4, 4), Mode Exploiting, Q -0.97 → -1.48\n",
      "Step 18: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploring, Q -1.10 → -1.27\n",
      "Step 19: State (5, 4), Action DOWN, Reward -1, Next (6, 4), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 20: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 21: State (7, 4), Action UP, Reward -1, Next (6, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 22: State (6, 4), Action UP, Reward -1, Next (5, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 23: State (5, 4), Action RIGHT, Reward -1, Next (5, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 24: State (5, 5), Action LEFT, Reward -1, Next (5, 4), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 25: State (5, 4), Action DOWN, Reward -1, Next (6, 4), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 26: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 27: State (7, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 28: State (7, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q -0.50 → -0.75\n",
      "Step 29: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 30: State (7, 5), Action LEFT, Reward -1, Next (7, 4), Mode Exploiting, Q 0.00 → -0.72\n",
      "Step 31: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 32: State (7, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploring, Q -0.50 → -0.75\n",
      "Step 33: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 0.00 → -0.50\n",
      "Step 34: State (7, 6), Action DOWN, Reward -1, Next (7, 6), Mode Exploring, Q 0.00 → -0.50\n",
      "Step 35: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploring, Q 0.00 → 50.00\n",
      "\n",
      "Episode 28\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.06 → -4.10\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.49 → -3.69\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -3.21 → -3.44\n",
      "Step 4: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -2.97 → -3.17\n",
      "Step 5: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -2.64 → -2.72\n",
      "Step 6: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -1.99 → -2.12\n",
      "Step 7: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -1.38 → -1.99\n",
      "Step 8: State (3, 2), Action LEFT, Reward -1, Next (3, 1), Mode Exploring, Q -1.79 → -2.62\n",
      "Step 9: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -2.71 → -3.10\n",
      "Step 10: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -2.77 → -3.45\n",
      "Step 11: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploring, Q -3.47 → -3.62\n",
      "Step 12: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.08 → -3.59\n",
      "Step 13: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -3.44 → -3.57\n",
      "Step 14: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.99 → -3.39\n",
      "Step 15: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploring, Q -3.10 → -3.46\n",
      "Step 16: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q -3.12 → -3.48\n",
      "Step 17: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.15 → -3.27\n",
      "Step 18: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.66 → -2.83\n",
      "Step 19: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.22 → -2.35\n",
      "Step 20: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -1.65 → -1.96\n",
      "Step 21: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q -1.43 → -1.90\n",
      "Step 22: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q -1.52 → -1.70\n",
      "Step 23: State (3, 6), Action LEFT, Reward -1, Next (3, 5), Mode Exploiting, Q -0.97 → -1.61\n",
      "Step 24: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploring, Q -1.38 → -1.73\n",
      "Step 25: State (3, 6), Action DOWN, Reward -1, Next (4, 6), Mode Exploiting, Q -1.20 → -1.44\n",
      "Step 26: State (4, 6), Action DOWN, Reward -1, Next (5, 6), Mode Exploiting, Q -0.75 → -3.12\n",
      "Step 27: State (5, 6), Action DOWN, Reward -10, Next (6, 6), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 29\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.10 → -4.21\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -3.68 → -3.92\n",
      "Step 3: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -3.51 → -3.89\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.63 → -3.66\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.00 → -3.27\n",
      "Step 6: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -2.83 → -3.25\n",
      "Step 7: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -2.98 → -3.69\n",
      "Step 8: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploring, Q -3.78 → -3.30\n",
      "Step 9: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploring, Q -2.02 → -2.10\n",
      "Step 10: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -1.31 → -1.49\n",
      "Step 11: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploiting, Q -0.75 → -1.31\n",
      "Step 12: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 13: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploiting, Q -0.97 → -1.32\n",
      "Step 14: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -0.75 → -1.36\n",
      "Step 15: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -1.08 → -1.48\n",
      "Step 16: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -0.97 → -1.52\n",
      "Step 17: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploring, Q -1.19 → -1.69\n",
      "Step 18: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploring, Q -1.32 → -1.80\n",
      "Step 19: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -1.41 → -1.88\n",
      "Step 20: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -1.49 → -1.84\n",
      "Step 21: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -1.31 → -1.75\n",
      "Step 22: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -1.32 → -1.65\n",
      "Step 23: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploring, Q -1.09 → -1.48\n",
      "Step 24: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 25: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -1.43 → -1.80\n",
      "Step 26: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -1.31 → -1.97\n",
      "Step 27: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploring, Q -1.80 → -1.99\n",
      "Step 28: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.31 → -1.65\n",
      "Step 29: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -1.10 → -1.55\n",
      "Step 30: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -1.55 → -1.82\n",
      "Step 31: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.21 → -1.44\n",
      "Step 32: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 33: State (7, 3), Action UP, Reward -1, Next (6, 3), Mode Exploiting, Q -0.75 → -1.10\n",
      "Step 34: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 35: State (6, 4), Action LEFT, Reward -1, Next (6, 3), Mode Exploiting, Q -0.50 → -1.08\n",
      "Step 36: State (6, 3), Action LEFT, Reward -1, Next (6, 2), Mode Exploiting, Q -0.72 → -1.30\n",
      "Step 37: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -0.97 → -1.53\n",
      "Step 38: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.20 → -1.74\n",
      "Step 39: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploiting, Q -1.43 → -1.82\n",
      "Step 40: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -1.35 → -1.77\n",
      "Step 41: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -1.32 → -1.80\n",
      "Step 42: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploring, Q -1.43 → -1.96\n",
      "Step 43: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploring, Q -1.65 → -1.98\n",
      "Step 44: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.44 → -1.76\n",
      "Step 45: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploiting, Q -1.20 → -1.54\n",
      "Step 46: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 47: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 48: State (6, 4), Action RIGHT, Reward -1, Next (6, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 49: State (6, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 50: State (7, 5), Action UP, Reward -1, Next (6, 5), Mode Exploiting, Q -0.50 → -0.97\n",
      "Step 51: State (6, 5), Action LEFT, Reward -1, Next (6, 4), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 52: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploring, Q -0.75 → -1.20\n",
      "Step 53: State (7, 4), Action UP, Reward -1, Next (6, 4), Mode Exploiting, Q -0.72 → -1.30\n",
      "Step 54: State (6, 4), Action UP, Reward -1, Next (5, 4), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 55: State (5, 4), Action RIGHT, Reward -1, Next (5, 5), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 56: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploring, Q -0.50 → -0.97\n",
      "Step 57: State (5, 6), Action UP, Reward -1, Next (4, 6), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 58: State (4, 6), Action RIGHT, Reward -1, Next (4, 7), Mode Exploiting, Q -0.75 → -1.36\n",
      "Step 59: State (4, 7), Action LEFT, Reward -1, Next (4, 6), Mode Exploiting, Q -1.09 → -1.48\n",
      "Step 60: State (4, 6), Action UP, Reward -1, Next (3, 6), Mode Exploiting, Q -0.97 → -1.63\n",
      "Step 61: State (3, 6), Action DOWN, Reward -1, Next (4, 6), Mode Exploiting, Q -1.44 → -2.63\n",
      "Step 62: State (4, 6), Action DOWN, Reward -1, Next (5, 6), Mode Exploring, Q -3.12 → -2.29\n",
      "Step 63: State (5, 6), Action LEFT, Reward -1, Next (5, 5), Mode Exploiting, Q -0.50 → -1.09\n",
      "Step 64: State (5, 5), Action DOWN, Reward -1, Next (6, 5), Mode Exploiting, Q -0.75 → -1.20\n",
      "Step 65: State (6, 5), Action UP, Reward -1, Next (5, 5), Mode Exploiting, Q -0.72 → -1.30\n",
      "Step 66: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploring, Q -0.97 → -1.21\n",
      "Step 67: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q -0.50 → 9.04\n",
      "Step 68: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 21.75 → 44.12\n",
      "Step 69: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploring, Q 75.00 → 87.50\n",
      "\n",
      "Episode 30\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -4.53 → -4.90\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -4.74 → -4.72\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.11 → -4.20\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.66 → -3.68\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -3.00 → -3.28\n",
      "Step 6: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -2.83 → -3.39\n",
      "Step 7: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.27 → -3.55\n",
      "Step 8: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -3.15 → -3.55\n",
      "Step 9: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -3.28 → -3.45\n",
      "Step 10: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploring, Q -2.92 → -3.31\n",
      "Step 11: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.00 → -2.61\n",
      "Step 12: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -1.36 → -1.78\n",
      "Step 13: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploiting, Q -1.32 → -1.79\n",
      "Step 14: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -1.39 → -1.83\n",
      "Step 15: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -1.41 → -1.64\n",
      "Step 16: State (4, 3), Action LEFT, Reward -1, Next (4, 2), Mode Exploiting, Q -0.97 → -1.65\n",
      "Step 17: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -1.48 → -1.88\n",
      "Step 18: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploiting, Q -1.43 → -2.02\n",
      "Step 19: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploiting, Q -1.79 → -2.19\n",
      "Step 20: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -1.78 → -2.23\n",
      "Step 21: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -1.88 → -2.13\n",
      "Step 22: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -1.52 → -1.81\n",
      "Step 23: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploiting, Q -1.21 → -1.92\n",
      "Step 24: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -1.81 → -2.05\n",
      "Step 25: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -1.43 → -1.70\n",
      "Step 26: State (6, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploring, Q -1.09 → -1.53\n",
      "Step 27: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q -1.08 → -1.62\n",
      "Step 28: State (7, 4), Action UP, Reward -1, Next (6, 4), Mode Exploring, Q -1.30 → -1.59\n",
      "Step 29: State (6, 4), Action RIGHT, Reward -1, Next (6, 5), Mode Exploring, Q -0.97 → -1.43\n",
      "Step 30: State (6, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploiting, Q -0.97 → -1.21\n",
      "Step 31: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q -0.50 → 21.75\n",
      "Step 32: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 50.00 → 75.00\n",
      "\n",
      "Episode 31\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.20 → -4.31\n",
      "Step 2: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploring, Q -3.80 → -4.01\n",
      "Step 3: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -3.59 → -3.95\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.69 → -3.82\n",
      "Step 5: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.29 → -3.62\n",
      "Step 6: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.62 → -3.88\n",
      "Step 7: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -3.48 → -3.68\n",
      "Step 8: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -3.21 → -3.73\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.62 → -3.78\n",
      "Step 10: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.27 → -3.36\n",
      "Step 11: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -2.72 → -2.83\n",
      "Step 12: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploring, Q -2.15 → -2.43\n",
      "Step 13: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -1.90 → -2.07\n",
      "Step 14: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -1.39 → -1.63\n",
      "Step 15: State (4, 4), Action LEFT, Reward -1, Next (4, 3), Mode Exploiting, Q -0.97 → -1.48\n",
      "Step 16: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -1.09 → -1.48\n",
      "Step 17: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q -0.97 → -1.43\n",
      "Step 18: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploiting, Q -0.97 → -1.53\n",
      "Step 19: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q -1.20 → -1.60\n",
      "Step 20: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q -1.10 → -1.49\n",
      "Step 21: State (5, 5), Action UP, Reward -1, Next (4, 5), Mode Exploiting, Q -0.97 → -1.55\n",
      "Step 22: State (4, 5), Action UP, Reward -1, Next (3, 5), Mode Exploring, Q -1.24 → -1.81\n",
      "Step 23: State (3, 5), Action LEFT, Reward -1, Next (3, 4), Mode Exploiting, Q -1.53 → -2.06\n",
      "Step 24: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploring, Q -1.76 → -2.07\n",
      "Step 25: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -1.54 → -1.94\n",
      "Step 26: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploring, Q -1.49 → -1.73\n",
      "Step 27: State (5, 5), Action LEFT, Reward -1, Next (5, 4), Mode Exploiting, Q -1.09 → -1.54\n",
      "Step 28: State (5, 4), Action DOWN, Reward -1, Next (6, 4), Mode Exploiting, Q -1.10 → -1.53\n",
      "Step 29: State (6, 4), Action LEFT, Reward -1, Next (6, 3), Mode Exploiting, Q -1.08 → -1.73\n",
      "Step 30: State (6, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploring, Q -1.53 → -1.76\n",
      "Step 31: State (7, 3), Action UP, Reward -1, Next (6, 3), Mode Exploring, Q -1.10 → -1.60\n",
      "Step 32: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploiting, Q -1.21 → -1.65\n",
      "Step 33: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q -1.20 → -1.44\n",
      "Step 34: State (7, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q -0.75 → -1.21\n",
      "Step 35: State (7, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q -1.21 → -1.54\n",
      "Step 36: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q -0.97 → 8.80\n",
      "Step 37: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 21.75 → 44.12\n",
      "Step 38: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 75.00 → 87.50\n",
      "\n",
      "Episode 32\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.21 → -4.30\n",
      "Step 2: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -3.76 → -4.15\n",
      "Step 3: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -3.92 → -4.16\n",
      "Step 4: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.78 → -3.90\n",
      "Step 5: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.36 → -3.45\n",
      "Step 6: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -2.83 → -2.87\n",
      "Step 7: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploring, Q -2.12 → -2.30\n",
      "Step 8: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploring, Q -1.64 → -1.86\n",
      "Step 9: State (4, 3), Action UP, Reward -1, Next (3, 3), Mode Exploiting, Q -1.19 → -1.79\n",
      "Step 10: State (3, 3), Action UP, Reward -1, Next (2, 3), Mode Exploiting, Q -1.55 → -2.31\n",
      "Step 11: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -2.30 → -2.44\n",
      "Step 12: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -1.75 → -2.04\n",
      "Step 13: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploiting, Q -1.47 → -2.07\n",
      "Step 14: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -1.86 → -2.10\n",
      "Step 15: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -1.48 → -1.81\n",
      "Step 16: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploiting, Q -1.27 → -1.67\n",
      "Step 17: State (5, 4), Action UP, Reward -1, Next (4, 4), Mode Exploiting, Q -1.19 → -1.69\n",
      "Step 18: State (4, 4), Action UP, Reward -1, Next (3, 4), Mode Exploiting, Q -1.32 → -2.09\n",
      "Step 19: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploring, Q -2.07 → -2.43\n",
      "Step 20: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -1.99 → -2.32\n",
      "Step 21: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -1.83 → -2.33\n",
      "Step 22: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -2.04 → -2.25\n",
      "Step 23: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -1.63 → -1.96\n",
      "Step 24: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q -1.43 → -1.88\n",
      "Step 25: State (4, 5), Action LEFT, Reward -1, Next (4, 4), Mode Exploring, Q -1.48 → -2.09\n",
      "Step 26: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploring, Q -1.88 → -2.13\n",
      "Step 27: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploiting, Q -1.53 → -1.88\n",
      "Step 28: State (4, 6), Action RIGHT, Reward -1, Next (4, 7), Mode Exploiting, Q -1.36 → -1.71\n",
      "Step 29: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q -1.16 → 18.77\n",
      "Step 30: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 44.12 → 60.94\n",
      "Step 31: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 87.50 → 93.75\n",
      "\n",
      "Episode 33\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.30 → -4.37\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.82 → -4.02\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -3.57 → -4.53\n",
      "Step 4: State (0, 3), Action RIGHT, Reward -10, Next (0, 4), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 34\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.31 → -4.31\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.68 → -3.84\n",
      "Step 3: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -3.32 → -3.65\n",
      "Step 4: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -3.65 → -3.88\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -3.45 → -3.72\n",
      "Step 6: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -3.31 → -3.33\n",
      "Step 7: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -2.61 → -2.98\n",
      "Step 8: State (3, 2), Action LEFT, Reward -1, Next (3, 1), Mode Exploring, Q -2.62 → -3.47\n",
      "Step 9: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q -3.69 → -3.79\n",
      "Step 10: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -3.22 → -3.56\n",
      "Step 11: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -3.56 → -3.74\n",
      "Step 12: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -3.25 → -3.47\n",
      "Step 13: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -2.98 → -3.00\n",
      "Step 14: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -2.23 → -2.57\n",
      "Step 15: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -2.13 → -2.48\n",
      "Step 16: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploring, Q -2.05 → -2.21\n",
      "Step 17: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -1.53 → -1.81\n",
      "Step 18: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -1.21 → -1.60\n",
      "Step 19: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q -1.10 → -1.55\n",
      "Step 20: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q -1.55 → -1.86\n",
      "Step 21: State (7, 3), Action LEFT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.31 → -1.85\n",
      "Step 22: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploring, Q -1.54 → -2.03\n",
      "Step 23: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploiting, Q -1.69 → -1.99\n",
      "Step 24: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -1.43 → -1.98\n",
      "Step 25: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -1.70 → -1.94\n",
      "Step 26: State (6, 3), Action LEFT, Reward -1, Next (6, 2), Mode Exploiting, Q -1.30 → -1.96\n",
      "Step 27: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -1.81 → -2.00\n",
      "Step 28: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -1.32 → -1.75\n",
      "Step 29: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -1.75 → -2.10\n",
      "Step 30: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -1.60 → -2.14\n",
      "Step 31: State (7, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploring, Q -1.86 → -2.15\n",
      "Step 32: State (7, 3), Action UP, Reward -1, Next (6, 3), Mode Exploiting, Q -1.60 → -2.04\n",
      "Step 33: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploiting, Q -1.65 → -1.97\n",
      "Step 34: State (6, 4), Action UP, Reward -1, Next (5, 4), Mode Exploiting, Q -1.43 → -1.76\n",
      "Step 35: State (5, 4), Action RIGHT, Reward -1, Next (5, 5), Mode Exploiting, Q -1.21 → -1.65\n",
      "Step 36: State (5, 5), Action DOWN, Reward -1, Next (6, 5), Mode Exploiting, Q -1.20 → -1.59\n",
      "Step 37: State (6, 5), Action LEFT, Reward -1, Next (6, 4), Mode Exploiting, Q -1.09 → -1.69\n",
      "Step 38: State (6, 4), Action RIGHT, Reward -1, Next (6, 5), Mode Exploiting, Q -1.43 → -1.76\n",
      "Step 39: State (6, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploring, Q -1.21 → 18.75\n",
      "Step 40: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 44.12 → 60.94\n",
      "Step 41: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 87.50 → 93.75\n",
      "\n",
      "Episode 35\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -4.31 → -4.41\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -3.90 → -4.17\n",
      "Step 3: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.84 → -3.99\n",
      "Step 4: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -3.49 → -4.04\n",
      "Step 5: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -3.99 → -4.09\n",
      "Step 6: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.55 → -3.76\n",
      "Step 7: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.30 → -3.01\n",
      "Step 8: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -1.92 → -2.82\n",
      "Step 9: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.01 → -2.95\n",
      "Step 10: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -2.10 → -2.28\n",
      "Step 11: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -1.62 → -2.03\n",
      "Step 12: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -2.03 → -2.25\n",
      "Step 13: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -1.63 → -1.94\n",
      "Step 14: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -1.39 → -1.84\n",
      "Step 15: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploiting, Q -1.43 → -1.94\n",
      "Step 16: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploiting, Q -1.62 → -2.32\n",
      "Step 17: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -2.25 → -2.45\n",
      "Step 18: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -1.84 → -2.01\n",
      "Step 19: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploring, Q -1.31 → -2.06\n",
      "Step 20: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploring, Q -2.02 → -2.49\n",
      "Step 21: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploiting, Q -2.19 → -3.16\n",
      "Step 22: State (3, 2), Action LEFT, Reward -1, Next (3, 1), Mode Exploring, Q -3.47 → -3.58\n",
      "Step 23: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.00 → -3.05\n",
      "Step 24: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -2.33 → -2.61\n",
      "Step 25: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -2.10 → -2.29\n",
      "Step 26: State (4, 3), Action LEFT, Reward -1, Next (4, 2), Mode Exploiting, Q -1.65 → -2.44\n",
      "Step 27: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -2.48 → -2.74\n",
      "Step 28: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -2.21 → -2.47\n",
      "Step 29: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploiting, Q -1.92 → -2.57\n",
      "Step 30: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -2.47 → -2.61\n",
      "Step 31: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -1.94 → -2.26\n",
      "Step 32: State (6, 3), Action DOWN, Reward -1, Next (7, 3), Mode Exploiting, Q -1.76 → -2.11\n",
      "Step 33: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q -1.62 → 2.65\n",
      "Step 34: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 8.80 → 31.32\n",
      "Step 35: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 60.94 → 29.97\n",
      "Step 36: State (7, 6), Action UP, Reward -10, Next (6, 6), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 36\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.37 → -4.56\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -4.16 → -4.30\n",
      "Step 3: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -3.82 → -3.91\n",
      "Step 4: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -3.33 → -3.54\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.05 → -3.18\n",
      "Step 6: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -2.57 → -3.02\n",
      "Step 7: State (4, 2), Action DOWN, Reward -1, Next (5, 2), Mode Exploiting, Q -2.74 → -2.99\n",
      "Step 8: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploring, Q -2.49 → -2.98\n",
      "Step 9: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q -2.75 → -2.97\n",
      "Step 10: State (4, 3), Action LEFT, Reward -1, Next (4, 2), Mode Exploring, Q -2.44 → -3.06\n",
      "Step 11: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q -2.97 → -2.79\n",
      "Step 12: State (4, 3), Action UP, Reward -1, Next (3, 3), Mode Exploiting, Q -1.79 → -2.41\n",
      "Step 13: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -2.25 → -2.45\n",
      "Step 14: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploiting, Q -1.83 → -2.27\n",
      "Step 15: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q -1.91 → -2.51\n",
      "Step 16: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.35 → -2.47\n",
      "Step 17: State (1, 5), Action LEFT, Reward -1, Next (1, 4), Mode Exploiting, Q -1.76 → -2.44\n",
      "Step 18: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -2.35 → -2.61\n",
      "Step 19: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -2.07 → -2.42\n",
      "Step 20: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -1.96 → -2.14\n",
      "Step 21: State (4, 4), Action LEFT, Reward -1, Next (4, 3), Mode Exploiting, Q -1.48 → -2.06\n",
      "Step 22: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -1.81 → -2.16\n",
      "Step 23: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploiting, Q -1.67 → -2.03\n",
      "Step 24: State (5, 4), Action DOWN, Reward -1, Next (6, 4), Mode Exploiting, Q -1.53 → -1.91\n",
      "Step 25: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q -1.44 → 12.88\n",
      "Step 26: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 31.32 → 28.65\n",
      "Step 27: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 29.97 → 56.67\n",
      "Step 28: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 93.75 → 96.88\n",
      "\n",
      "Episode 37\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.41 → -4.51\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -4.00 → -4.53\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.51 → -4.59\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploring, Q -4.09 → -4.29\n",
      "Step 5: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -3.88 → -4.11\n",
      "Step 6: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -3.72 → -3.95\n",
      "Step 7: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploring, Q -3.54 → -3.67\n",
      "Step 8: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -3.10 → -3.58\n",
      "Step 9: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -3.39 → -3.89\n",
      "Step 10: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -3.76 → -3.71\n",
      "Step 11: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -2.95 → -3.00\n",
      "Step 12: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -2.28 → -2.47\n",
      "Step 13: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploiting, Q -1.85 → -2.46\n",
      "Step 14: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -2.30 → -2.69\n",
      "Step 15: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploring, Q -2.69 → -2.96\n",
      "Step 16: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -2.47 → -2.61\n",
      "Step 17: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -1.94 → -2.30\n",
      "Step 18: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploring, Q -1.84 → -2.16\n",
      "Step 19: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.65 → -1.99\n",
      "Step 20: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -1.48 → -2.11\n",
      "Step 21: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploiting, Q -1.94 → -2.28\n",
      "Step 22: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -1.80 → -2.21\n",
      "Step 23: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -2.21 → -2.49\n",
      "Step 24: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q -1.96 → -2.28\n",
      "Step 25: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -1.77 → -2.36\n",
      "Step 26: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.16 → -2.47\n",
      "Step 27: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -1.97 → -2.37\n",
      "Step 28: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.37 → -2.58\n",
      "Step 29: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.99 → -2.29\n",
      "Step 30: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.76 → -2.29\n",
      "Step 31: State (7, 2), Action UP, Reward -1, Next (6, 2), Mode Exploring, Q -2.03 → -2.41\n",
      "Step 32: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploiting, Q -1.99 → -2.30\n",
      "Step 33: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q -1.80 → -2.19\n",
      "Step 34: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -1.75 → -2.27\n",
      "Step 35: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -1.98 → -2.31\n",
      "Step 36: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -1.82 → -2.23\n",
      "Step 37: State (7, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -2.23 → -2.43\n",
      "Step 38: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploiting, Q -1.82 → -2.30\n",
      "Step 39: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -1.98 → -2.39\n",
      "Step 40: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -2.00 → -2.28\n",
      "Step 41: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.74 → -2.32\n",
      "Step 42: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -2.11 → -2.45\n",
      "Step 43: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -1.99 → -2.39\n",
      "Step 44: State (7, 0), Action LEFT, Reward -1, Next (7, 0), Mode Exploiting, Q -2.39 → -2.72\n",
      "Step 45: State (7, 0), Action UP, Reward -1, Next (6, 0), Mode Exploiting, Q -2.28 → -2.67\n",
      "Step 46: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q -2.28 → -2.70\n",
      "Step 47: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploring, Q -2.36 → -2.79\n",
      "Step 48: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploring, Q -2.47 → -2.76\n",
      "Step 49: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -2.29 → -2.68\n",
      "Step 50: State (7, 1), Action UP, Reward -1, Next (6, 1), Mode Exploring, Q -2.30 → -2.64\n",
      "Step 51: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q -2.19 → -2.44\n",
      "Step 52: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -1.88 → -2.34\n",
      "Step 53: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -2.01 → -2.43\n",
      "Step 54: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploiting, Q -2.06 → -2.70\n",
      "Step 55: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -2.61 → -2.96\n",
      "Step 56: State (6, 2), Action UP, Reward -1, Next (5, 2), Mode Exploring, Q -2.57 → -3.12\n",
      "Step 57: State (5, 2), Action DOWN, Reward -1, Next (6, 2), Mode Exploiting, Q -2.96 → -3.00\n",
      "Step 58: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -2.26 → -2.51\n",
      "Step 59: State (6, 3), Action LEFT, Reward -1, Next (6, 2), Mode Exploiting, Q -1.96 → -2.51\n",
      "Step 60: State (6, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -2.28 → -2.59\n",
      "Step 61: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -2.10 → -2.49\n",
      "Step 62: State (7, 2), Action DOWN, Reward -1, Next (7, 2), Mode Exploiting, Q -2.49 → -2.71\n",
      "Step 63: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -2.14 → -0.38\n",
      "Step 64: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 2.65 → 0.11\n",
      "Step 65: State (7, 4), Action UP, Reward -1, Next (6, 4), Mode Exploring, Q -1.59 → -2.09\n",
      "Step 66: State (6, 4), Action RIGHT, Reward -1, Next (6, 5), Mode Exploring, Q -1.76 → 7.06\n",
      "Step 67: State (6, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploiting, Q 18.75 → 34.38\n",
      "Step 68: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 56.67 → 25.59\n",
      "Step 69: State (7, 6), Action UP, Reward -10, Next (6, 6), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 38\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.56 → -4.59\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.02 → -4.17\n",
      "Step 3: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -3.68 → -3.89\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.45 → -3.48\n",
      "Step 5: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -2.80 → -5.27\n",
      "Step 6: State (0, 3), Action RIGHT, Reward -10, Next (0, 4), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 39\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.59 → -4.66\n",
      "Step 2: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -4.15 → -4.64\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.59 → -4.73\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploring, Q -4.29 → -4.32\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.71 → -3.71\n",
      "Step 6: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.00 → -3.18\n",
      "Step 7: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -2.61 → -2.84\n",
      "Step 8: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -2.30 → -2.69\n",
      "Step 9: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploiting, Q -2.32 → -2.76\n",
      "Step 10: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -2.43 → -2.74\n",
      "Step 11: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -2.27 → -2.67\n",
      "Step 12: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -2.31 → -2.69\n",
      "Step 13: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -2.29 → -1.82\n",
      "Step 14: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -0.38 → -0.64\n",
      "Step 15: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 0.11 → 12.45\n",
      "Step 16: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 28.65 → 25.34\n",
      "Step 17: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 25.59 → 55.89\n",
      "Step 18: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 96.88 → 98.44\n",
      "\n",
      "Episode 40\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.66 → -4.70\n",
      "Step 2: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -4.15 → -4.44\n",
      "Step 3: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -4.44 → -4.59\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.17 → -4.29\n",
      "Step 5: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -3.80 → -4.33\n",
      "Step 6: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.29 → -4.60\n",
      "Step 7: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploring, Q -4.33 → -4.60\n",
      "Step 8: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.30 → -4.40\n",
      "Step 9: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -3.89 → -4.25\n",
      "Step 10: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.01 → -4.26\n",
      "Step 11: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.90 → -4.02\n",
      "Step 12: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.48 → -3.51\n",
      "Step 13: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.83 → -3.01\n",
      "Step 14: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploiting, Q -2.43 → -3.00\n",
      "Step 15: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -2.87 → -3.03\n",
      "Step 16: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -2.43 → -2.66\n",
      "Step 17: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploiting, Q -2.09 → -2.64\n",
      "Step 18: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -2.44 → -2.75\n",
      "Step 19: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -2.29 → -2.62\n",
      "Step 20: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -2.16 → -2.49\n",
      "Step 21: State (4, 4), Action DOWN, Reward -1, Next (5, 4), Mode Exploiting, Q -2.03 → -2.25\n",
      "Step 22: State (5, 4), Action RIGHT, Reward -1, Next (5, 5), Mode Exploiting, Q -1.65 → -1.87\n",
      "Step 23: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q -1.21 → 2.96\n",
      "Step 24: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 9.04 → 31.44\n",
      "Step 25: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploring, Q 60.94 → 72.16\n",
      "Step 26: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 93.75 → 96.88\n",
      "\n",
      "Episode 41\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.70 → -4.83\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.40 → -4.46\n",
      "Step 3: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -3.91 → -4.01\n",
      "Step 4: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -3.45 → -4.14\n",
      "Step 5: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploring, Q -4.25 → -4.50\n",
      "Step 6: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.17 → -4.47\n",
      "Step 7: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.47 → -4.65\n",
      "Step 8: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.26 → -4.41\n",
      "Step 9: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -3.95 → -4.48\n",
      "Step 10: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.46 → -4.53\n",
      "Step 11: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -4.01 → -4.25\n",
      "Step 12: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -3.89 → -4.11\n",
      "Step 13: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.71 → -3.78\n",
      "Step 14: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploring, Q -3.18 → -3.35\n",
      "Step 15: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -2.82 → -3.42\n",
      "Step 16: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.35 → -3.45\n",
      "Step 17: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -2.84 → -3.02\n",
      "Step 18: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -2.45 → -2.83\n",
      "Step 19: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -2.83 → -3.02\n",
      "Step 20: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploiting, Q -2.46 → -3.06\n",
      "Step 21: State (4, 0), Action LEFT, Reward -1, Next (4, 0), Mode Exploiting, Q -2.96 → -5.35\n",
      "Step 22: State (4, 0), Action RIGHT, Reward -10, Next (4, 1), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 42\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -4.72 → -4.98\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -4.98 → -5.12\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.73 → -4.81\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.32 → -4.36\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -3.78 → -3.95\n",
      "Step 6: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploring, Q -3.45 → -3.59\n",
      "Step 7: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.02 → -3.22\n",
      "Step 8: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -2.69 → -3.09\n",
      "Step 9: State (6, 0), Action UP, Reward -1, Next (5, 0), Mode Exploring, Q -2.76 → -3.11\n",
      "Step 10: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -2.74 → -2.92\n",
      "Step 11: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -2.34 → -2.99\n",
      "Step 12: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -2.92 → -3.16\n",
      "Step 13: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploring, Q -2.67 → -2.91\n",
      "Step 14: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -2.39 → -2.73\n",
      "Step 15: State (6, 2), Action LEFT, Reward -1, Next (6, 1), Mode Exploiting, Q -2.30 → -2.75\n",
      "Step 16: State (6, 1), Action UP, Reward -1, Next (5, 1), Mode Exploiting, Q -2.44 → -2.94\n",
      "Step 17: State (5, 1), Action RIGHT, Reward -1, Next (5, 2), Mode Exploring, Q -2.70 → -3.20\n",
      "Step 18: State (5, 2), Action UP, Reward -1, Next (4, 2), Mode Exploiting, Q -2.98 → -3.25\n",
      "Step 19: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q -2.79 → -2.98\n",
      "Step 20: State (4, 3), Action UP, Reward -1, Next (3, 3), Mode Exploring, Q -2.41 → -2.81\n",
      "Step 21: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploring, Q -2.45 → -2.66\n",
      "Step 22: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploiting, Q -2.07 → -2.31\n",
      "Step 23: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploiting, Q -1.73 → -2.03\n",
      "Step 24: State (3, 6), Action UP, Reward -1, Next (2, 6), Mode Exploiting, Q -1.47 → -1.95\n",
      "Step 25: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -1.58 → -1.99\n",
      "Step 26: State (2, 7), Action LEFT, Reward -1, Next (2, 6), Mode Exploiting, Q -1.55 → -2.02\n",
      "Step 27: State (2, 6), Action LEFT, Reward -1, Next (2, 5), Mode Exploiting, Q -1.65 → -2.17\n",
      "Step 28: State (2, 5), Action LEFT, Reward -1, Next (2, 4), Mode Exploring, Q -1.88 → -2.42\n",
      "Step 29: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -2.18 → -2.42\n",
      "Step 30: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploiting, Q -1.84 → -2.34\n",
      "Step 31: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploring, Q -2.04 → -2.20\n",
      "Step 32: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -1.50 → -1.98\n",
      "Step 33: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -1.63 → -2.07\n",
      "Step 34: State (2, 7), Action UP, Reward -1, Next (1, 7), Mode Exploring, Q -1.69 → -2.25\n",
      "Step 35: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploring, Q -2.02 → -2.25\n",
      "Step 36: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -1.65 → -2.12\n",
      "Step 37: State (0, 7), Action LEFT, Reward -1, Next (0, 6), Mode Exploiting, Q -1.77 → -2.22\n",
      "Step 38: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploring, Q -1.87 → -2.18\n",
      "Step 39: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -1.65 → -2.07\n",
      "Step 40: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploiting, Q -1.66 → -2.19\n",
      "Step 41: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -1.92 → -2.24\n",
      "Step 42: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -1.73 → -2.17\n",
      "Step 43: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploiting, Q -1.80 → -2.26\n",
      "Step 44: State (1, 7), Action LEFT, Reward -1, Next (1, 6), Mode Exploiting, Q -1.91 → -2.46\n",
      "Step 45: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploring, Q -2.24 → -2.48\n",
      "Step 46: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -1.91 → -2.44\n",
      "Step 47: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploring, Q -2.18 → -2.48\n",
      "Step 48: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -1.98 → -2.42\n",
      "Step 49: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -2.07 → -2.25\n",
      "Step 50: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -1.58 → -2.01\n",
      "Step 51: State (2, 7), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -2.01 → -2.23\n",
      "Step 52: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q -1.63 → -1.91\n",
      "Step 53: State (3, 7), Action LEFT, Reward -1, Next (3, 6), Mode Exploring, Q -1.32 → -1.89\n",
      "Step 54: State (3, 6), Action LEFT, Reward -1, Next (3, 5), Mode Exploiting, Q -1.61 → -2.14\n",
      "Step 55: State (3, 5), Action UP, Reward -1, Next (2, 5), Mode Exploiting, Q -1.86 → -2.52\n",
      "Step 56: State (2, 5), Action LEFT, Reward -1, Next (2, 4), Mode Exploring, Q -2.42 → -2.80\n",
      "Step 57: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -2.42 → -2.67\n",
      "Step 58: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -2.14 → -2.50\n",
      "Step 59: State (4, 4), Action LEFT, Reward -1, Next (4, 3), Mode Exploiting, Q -2.06 → -2.65\n",
      "Step 60: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -2.49 → -2.69\n",
      "Step 61: State (4, 4), Action UP, Reward -1, Next (3, 4), Mode Exploiting, Q -2.09 → -2.57\n",
      "Step 62: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploiting, Q -2.27 → -2.72\n",
      "Step 63: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -2.42 → -2.76\n",
      "Step 64: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploring, Q -2.34 → -2.55\n",
      "Step 65: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -1.96 → -2.32\n",
      "Step 66: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -1.86 → -2.36\n",
      "Step 67: State (3, 5), Action LEFT, Reward -1, Next (3, 4), Mode Exploring, Q -2.06 → -2.57\n",
      "Step 68: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploiting, Q -2.31 → -2.53\n",
      "Step 69: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -1.94 → -2.25\n",
      "Step 70: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q -1.73 → -0.03\n",
      "Step 71: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 2.96 → 15.13\n",
      "Step 72: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 31.44 → 47.69\n",
      "Step 73: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 72.16 → 35.58\n",
      "Step 74: State (6, 7), Action UP, Reward -1, Next (5, 7), Mode Exploring, Q 0.00 → 15.51\n",
      "Step 75: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 35.58 → 60.88\n",
      "Step 76: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 96.88 → 98.44\n",
      "\n",
      "Episode 43\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.81 → -4.87\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.36 → -4.46\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -3.95 → -4.03\n",
      "Step 4: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -3.47 → -3.67\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.18 → -3.26\n",
      "Step 6: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -2.61 → -3.00\n",
      "Step 7: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploring, Q -2.66 → -2.97\n",
      "Step 8: State (3, 4), Action RIGHT, Reward -1, Next (3, 5), Mode Exploring, Q -2.53 → -2.68\n",
      "Step 9: State (3, 5), Action RIGHT, Reward -1, Next (3, 6), Mode Exploiting, Q -2.03 → -2.26\n",
      "Step 10: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q -1.66 → -2.14\n",
      "Step 11: State (3, 7), Action RIGHT, Reward -1, Next (3, 7), Mode Exploring, Q -1.80 → -2.12\n",
      "Step 12: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q -1.60 → 7.15\n",
      "Step 13: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 18.77 → 8.45\n",
      "Step 14: State (5, 7), Action RIGHT, Reward -1, Next (5, 7), Mode Exploring, Q -0.97 → 26.41\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 60.88 → 74.24\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 98.44 → 99.22\n",
      "\n",
      "Episode 44\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.83 → -4.95\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.53 → -4.58\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.02 → -4.09\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.51 → -3.61\n",
      "Step 5: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.01 → -3.11\n",
      "Step 6: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.47 → -2.72\n",
      "Step 7: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploring, Q -2.20 → -2.53\n",
      "Step 8: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -2.07 → -2.30\n",
      "Step 9: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q -1.70 → -2.23\n",
      "Step 10: State (3, 6), Action UP, Reward -1, Next (2, 6), Mode Exploiting, Q -1.95 → -2.37\n",
      "Step 11: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploring, Q -1.99 → -2.36\n",
      "Step 12: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q -1.91 → 1.76\n",
      "Step 13: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 7.15 → 6.88\n",
      "Step 14: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 8.45 → 37.13\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 74.24 → 81.27\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.22 → 99.61\n",
      "\n",
      "Episode 45\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.87 → -4.92\n",
      "Step 2: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.41 → -4.55\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.09 → -4.16\n",
      "Step 4: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.59 → -4.04\n",
      "Step 5: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q -3.89 → -4.07\n",
      "Step 6: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.61 → -3.67\n",
      "Step 7: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -3.03 → -3.16\n",
      "Step 8: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploiting, Q -2.55 → -3.17\n",
      "Step 9: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.08 → -3.69\n",
      "Step 10: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q -3.67 → -3.73\n",
      "Step 11: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.11 → -3.23\n",
      "Step 12: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -2.61 → -2.94\n",
      "Step 13: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q -2.51 → -2.98\n",
      "Step 14: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.72 → -2.91\n",
      "Step 15: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -2.32 → -2.51\n",
      "Step 16: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q -1.90 → -2.42\n",
      "Step 17: State (2, 6), Action LEFT, Reward -1, Next (2, 5), Mode Exploiting, Q -2.17 → -2.65\n",
      "Step 18: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -2.36 → -2.69\n",
      "Step 19: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -2.25 → -1.64\n",
      "Step 20: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q -0.03 → 6.29\n",
      "Step 21: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 15.13 → 3.69\n",
      "Step 22: State (5, 6), Action DOWN, Reward -10, Next (6, 6), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 46\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -4.90 → -5.16\n",
      "Step 2: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -5.16 → -5.29\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.92 → -4.96\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.46 → -4.51\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -3.95 → -4.12\n",
      "Step 6: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -3.67 → -3.80\n",
      "Step 7: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploring, Q -3.26 → -3.48\n",
      "Step 8: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -3.00 → -3.04\n",
      "Step 9: State (3, 3), Action UP, Reward -1, Next (2, 3), Mode Exploiting, Q -2.31 → -2.85\n",
      "Step 10: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -2.66 → -3.02\n",
      "Step 11: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploiting, Q -2.64 → -3.06\n",
      "Step 12: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -2.75 → -3.05\n",
      "Step 13: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploring, Q -2.62 → -3.02\n",
      "Step 14: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -2.69 → -2.80\n",
      "Step 15: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q -2.13 → 1.27\n",
      "Step 16: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploring, Q 6.29 → 4.31\n",
      "Step 17: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 3.69 → 22.81\n",
      "Step 18: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 47.69 → 59.92\n",
      "Step 19: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 81.27 → 84.96\n",
      "Step 20: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.61 → 99.80\n",
      "\n",
      "Episode 47\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.95 → -5.04\n",
      "Step 2: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -4.59 → -4.86\n",
      "Step 3: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.58 → -4.66\n",
      "Step 4: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.16 → -4.26\n",
      "Step 5: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -3.73 → -4.28\n",
      "Step 6: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -4.25 → -4.34\n",
      "Step 7: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -3.80 → -3.97\n",
      "Step 8: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploring, Q -3.48 → -3.60\n",
      "Step 9: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -3.02 → -3.43\n",
      "Step 10: State (4, 2), Action UP, Reward -1, Next (3, 2), Mode Exploring, Q -3.16 → -5.45\n",
      "Step 11: State (3, 2), Action UP, Reward -10, Next (2, 2), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 48\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -4.96 → -5.01\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.51 → -4.57\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -4.03 → -4.11\n",
      "Step 4: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -3.55 → -4.09\n",
      "Step 5: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -4.04 → -4.56\n",
      "Step 6: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -4.53 → -5.02\n",
      "Step 7: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.01 → -5.05\n",
      "Step 8: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.55 → -4.69\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.26 → -4.31\n",
      "Step 10: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.73 → -3.79\n",
      "Step 11: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -3.16 → -3.44\n",
      "Step 12: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -3.02 → -3.21\n",
      "Step 13: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -2.67 → -2.93\n",
      "Step 14: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploiting, Q -2.43 → -2.76\n",
      "Step 15: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -2.32 → -3.03\n",
      "Step 16: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -3.04 → -3.30\n",
      "Step 17: State (3, 3), Action UP, Reward -1, Next (2, 3), Mode Exploiting, Q -2.85 → -3.30\n",
      "Step 18: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -3.05 → -3.36\n",
      "Step 19: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -2.97 → -3.11\n",
      "Step 20: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -2.50 → -1.18\n",
      "Step 21: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 1.27 → 2.07\n",
      "Step 22: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 4.31 → 11.92\n",
      "Step 23: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 22.81 → 37.86\n",
      "Step 24: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 59.92 → 67.69\n",
      "Step 25: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 84.96 → 86.89\n",
      "Step 26: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.80 → 99.90\n",
      "\n",
      "Episode 49\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.04 → -5.09\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.60 → -4.54\n",
      "Step 3: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -3.88 → -4.18\n",
      "Step 4: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -4.18 → -4.42\n",
      "Step 5: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -4.07 → -4.24\n",
      "Step 6: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.79 → -3.94\n",
      "Step 7: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -3.44 → -3.64\n",
      "Step 8: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploiting, Q -3.17 → -4.46\n",
      "Step 9: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q -5.27 → -4.56\n",
      "Step 10: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -3.17 → -3.54\n",
      "Step 11: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.23 → -3.42\n",
      "Step 12: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.91 → -3.05\n",
      "Step 13: State (1, 5), Action LEFT, Reward -1, Next (1, 4), Mode Exploiting, Q -2.44 → -3.04\n",
      "Step 14: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -2.94 → -3.34\n",
      "Step 15: State (2, 4), Action LEFT, Reward -1, Next (2, 3), Mode Exploring, Q -3.06 → -3.54\n",
      "Step 16: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploring, Q -3.36 → -3.54\n",
      "Step 17: State (3, 3), Action DOWN, Reward -1, Next (4, 3), Mode Exploiting, Q -3.02 → -3.27\n",
      "Step 18: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -2.80 → -0.97\n",
      "Step 19: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 2.07 → 5.90\n",
      "Step 20: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 11.92 → 22.50\n",
      "Step 21: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 37.86 → 48.89\n",
      "Step 22: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 67.69 → 72.45\n",
      "Step 23: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 86.89 → 87.90\n",
      "Step 24: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.90 → 99.95\n",
      "\n",
      "Episode 50\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.05 → -5.08\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.57 → -4.63\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -4.11 → -4.21\n",
      "Step 4: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploring, Q -3.67 → -4.58\n",
      "Step 5: State (3, 1), Action DOWN, Reward -10, Next (4, 1), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 51\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.08 → -5.13\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.63 → -4.87\n",
      "Step 3: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploring, Q -4.56 → -4.97\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploring, Q -4.87 → -4.79\n",
      "Step 5: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.11 → -4.41\n",
      "Step 6: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.41 → -4.56\n",
      "Step 7: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.12 → -4.35\n",
      "Step 8: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -3.97 → -4.09\n",
      "Step 9: State (3, 1), Action UP, Reward -1, Next (2, 1), Mode Exploiting, Q -3.58 → -4.13\n",
      "Step 10: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.09 → -4.17\n",
      "Step 11: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.60 → -3.79\n",
      "Step 12: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -3.30 → -3.51\n",
      "Step 13: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.03 → -3.56\n",
      "Step 14: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -3.43 → -3.56\n",
      "Step 15: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q -2.98 → -2.43\n",
      "Step 16: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q -0.97 → 1.67\n",
      "Step 17: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 5.90 → 1.60\n",
      "Step 18: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploring, Q -1.88 → -2.16\n",
      "Step 19: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q -1.60 → 8.83\n",
      "Step 20: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 22.50 → 32.75\n",
      "Step 21: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 48.89 → 56.55\n",
      "Step 22: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 72.45 → 75.28\n",
      "Step 23: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 87.90 → 50.43\n",
      "Step 24: State (6, 7), Action UP, Reward -1, Next (5, 7), Mode Exploring, Q 15.51 → 29.95\n",
      "Step 25: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 50.43 → 69.69\n",
      "Step 26: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.95 → 99.98\n",
      "\n",
      "Episode 52\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.09 → -5.09\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.54 → -4.68\n",
      "Step 3: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -4.24 → -4.39\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.94 → -4.01\n",
      "Step 5: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.42 → -3.56\n",
      "Step 6: State (1, 4), Action LEFT, Reward -1, Next (1, 3), Mode Exploiting, Q -3.00 → -3.61\n",
      "Step 7: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.56 → -3.79\n",
      "Step 8: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploring, Q -3.34 → -3.42\n",
      "Step 9: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploiting, Q -2.76 → -2.97\n",
      "Step 10: State (2, 5), Action RIGHT, Reward -1, Next (2, 6), Mode Exploiting, Q -2.42 → -2.70\n",
      "Step 11: State (2, 6), Action UP, Reward -1, Next (1, 6), Mode Exploiting, Q -2.19 → -2.63\n",
      "Step 12: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -2.30 → -2.65\n",
      "Step 13: State (2, 6), Action DOWN, Reward -1, Next (3, 6), Mode Exploiting, Q -2.23 → -2.58\n",
      "Step 14: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploring, Q -2.14 → 1.52\n",
      "Step 15: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 6.88 → 19.65\n",
      "Step 16: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 37.13 → 49.43\n",
      "Step 17: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 69.69 → 79.34\n",
      "Step 18: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.98 → 99.99\n",
      "\n",
      "Episode 53\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.09 → -5.13\n",
      "Step 2: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -4.64 → -5.12\n",
      "Step 3: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -5.12 → -5.36\n",
      "Step 4: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -5.36 → -5.49\n",
      "Step 5: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.13 → -5.16\n",
      "Step 6: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.65 → -4.92\n",
      "Step 7: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.92 → -5.07\n",
      "Step 8: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.69 → -4.78\n",
      "Step 9: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.31 → -4.46\n",
      "Step 10: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.01 → -4.15\n",
      "Step 11: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -3.64 → -3.77\n",
      "Step 12: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -3.21 → -3.43\n",
      "Step 13: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -2.93 → -3.21\n",
      "Step 14: State (3, 4), Action LEFT, Reward -1, Next (3, 3), Mode Exploring, Q -2.76 → -3.28\n",
      "Step 15: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -3.11 → -2.58\n",
      "Step 16: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -1.18 → -0.37\n",
      "Step 17: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 1.60 → 15.04\n",
      "Step 18: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 32.75 → 15.18\n",
      "Step 19: State (5, 5), Action LEFT, Reward -1, Next (5, 4), Mode Exploring, Q -1.54 → -2.03\n",
      "Step 20: State (5, 4), Action UP, Reward -1, Next (4, 4), Mode Exploiting, Q -1.69 → 5.42\n",
      "Step 21: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 15.04 → 13.85\n",
      "Step 22: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 15.18 → 32.54\n",
      "Step 23: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 56.55 → 61.65\n",
      "Step 24: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 75.28 → 72.84\n",
      "Step 25: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 79.34 → 84.16\n",
      "Step 26: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.99 → 99.99\n",
      "\n",
      "Episode 54\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.13 → -5.16\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.66 → -4.78\n",
      "Step 3: State (1, 1), Action DOWN, Reward -1, Next (2, 1), Mode Exploiting, Q -4.34 → -6.04\n",
      "Step 4: State (2, 1), Action RIGHT, Reward -10, Next (2, 2), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 55\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.16 → -5.34\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -5.02 → -5.33\n",
      "Step 3: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.16 → -5.19\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.68 → -4.82\n",
      "Step 5: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -4.39 → -4.52\n",
      "Step 6: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -4.04 → -4.51\n",
      "Step 7: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -4.42 → -4.78\n",
      "Step 8: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploring, Q -4.60 → -4.95\n",
      "Step 9: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.78 → -4.90\n",
      "Step 10: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.46 → -4.60\n",
      "Step 11: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.15 → -4.23\n",
      "Step 12: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q -3.69 → -4.25\n",
      "Step 13: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.23 → -4.67\n",
      "Step 14: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q -4.56 → -4.31\n",
      "Step 15: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -3.39 → -3.72\n",
      "Step 16: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -3.72 → -3.92\n",
      "Step 17: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -3.46 → -4.27\n",
      "Step 18: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -4.53 → -4.36\n",
      "Step 19: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -3.54 → -3.96\n",
      "Step 20: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -3.77 → -3.92\n",
      "Step 21: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -3.43 → -3.55\n",
      "Step 22: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploring, Q -2.97 → -3.14\n",
      "Step 23: State (2, 5), Action UP, Reward -1, Next (1, 5), Mode Exploiting, Q -2.55 → -2.91\n",
      "Step 24: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -2.51 → -2.97\n",
      "Step 25: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -2.69 → -2.58\n",
      "Step 26: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q -1.64 → 13.32\n",
      "Step 27: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 32.54 → 43.51\n",
      "Step 28: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 61.65 → 63.10\n",
      "Step 29: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 72.84 → 73.79\n",
      "Step 30: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 84.16 → 86.58\n",
      "Step 31: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 99.99 → 100.00\n",
      "\n",
      "Episode 56\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.19 → -5.26\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.82 → -4.87\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -4.36 → -4.44\n",
      "Step 4: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -3.92 → -4.22\n",
      "Step 5: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploiting, Q -4.22 → -4.51\n",
      "Step 6: State (0, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q -4.51 → -6.69\n",
      "Step 7: State (0, 3), Action RIGHT, Reward -10, Next (0, 4), Mode Exploring, Q -8.75 → -9.38\n",
      "\n",
      "Episode 57\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -5.29 → -5.51\n",
      "Step 2: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.26 → -5.32\n",
      "Step 3: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -4.86 → -5.11\n",
      "Step 4: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -5.11 → -5.25\n",
      "Step 5: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.87 → -4.97\n",
      "Step 6: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q -4.52 → -4.68\n",
      "Step 7: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploring, Q -4.28 → -4.66\n",
      "Step 8: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -4.48 → -4.95\n",
      "Step 9: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -4.90 → -4.98\n",
      "Step 10: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.50 → -4.90\n",
      "Step 11: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.78 → -4.96\n",
      "Step 12: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.60 → -5.05\n",
      "Step 13: State (1, 2), Action DOWN, Reward -10, Next (2, 2), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 58\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.32 → -5.40\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploring, Q -4.98 → -5.19\n",
      "Step 3: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -4.90 → -5.11\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.79 → -4.79\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -4.21 → -4.22\n",
      "Step 6: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.59 → -3.74\n",
      "Step 7: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.22 → -3.49\n",
      "Step 8: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploring, Q -3.06 → -3.57\n",
      "Step 9: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -3.42 → -3.89\n",
      "Step 10: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -3.74 → -4.06\n",
      "Step 11: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -4.06 → -4.21\n",
      "Step 12: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.74 → -3.94\n",
      "Step 13: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.49 → -3.61\n",
      "Step 14: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -3.02 → -3.37\n",
      "Step 15: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploiting, Q -3.37 → -3.58\n",
      "Step 16: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -3.09 → -3.16\n",
      "Step 17: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -2.49 → -2.86\n",
      "Step 18: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -2.86 → -3.22\n",
      "Step 19: State (6, 0), Action LEFT, Reward -1, Next (6, 0), Mode Exploring, Q -3.22 → -3.32\n",
      "Step 20: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q -2.70 → -3.06\n",
      "Step 21: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -2.69 → -2.66\n",
      "Step 22: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.82 → -1.70\n",
      "Step 23: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q -0.64 → 4.78\n",
      "Step 24: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 12.45 → 4.78\n",
      "Step 25: State (7, 4), Action UP, Reward -1, Next (6, 4), Mode Exploring, Q -2.09 → 4.25\n",
      "Step 26: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q 12.88 → 17.34\n",
      "Step 27: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 25.34 → 11.84\n",
      "Step 28: State (7, 5), Action LEFT, Reward -1, Next (7, 4), Mode Exploring, Q -0.72 → 4.47\n",
      "Step 29: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 11.84 → 30.57\n",
      "Step 30: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 55.89 → 71.74\n",
      "Step 31: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 98.44 → 99.22\n",
      "\n",
      "Episode 59\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.34 → -5.57\n",
      "Step 2: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -5.33 → -5.59\n",
      "Step 3: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.40 → -5.56\n",
      "Step 4: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -5.25 → -5.36\n",
      "Step 5: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.97 → -4.98\n",
      "Step 6: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -4.44 → -4.51\n",
      "Step 7: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -3.96 → -4.42\n",
      "Step 8: State (1, 3), Action UP, Reward -1, Next (0, 3), Mode Exploring, Q -4.31 → -4.64\n",
      "Step 9: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploring, Q -4.42 → -4.41\n",
      "Step 10: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -3.79 → -4.64\n",
      "Step 11: State (1, 4), Action UP, Reward -10, Next (0, 4), Mode Exploring, Q -5.00 → -7.50\n",
      "\n",
      "Episode 60\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploiting, Q -5.49 → -5.71\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -5.71 → -5.84\n",
      "Step 3: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -5.51 → -5.74\n",
      "Step 4: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -5.74 → -5.87\n",
      "Step 5: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.56 → -5.59\n",
      "Step 6: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -5.12 → -5.57\n",
      "Step 7: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.57 → -5.44\n",
      "Step 8: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.79 → -4.79\n",
      "Step 9: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -4.22 → -4.38\n",
      "Step 10: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -3.94 → -4.09\n",
      "Step 11: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.61 → -3.73\n",
      "Step 12: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -3.16 → -3.33\n",
      "Step 13: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.76 → -3.09\n",
      "Step 14: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploring, Q -2.68 → -2.60\n",
      "Step 15: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -1.70 → 0.80\n",
      "Step 16: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 4.78 → 4.04\n",
      "Step 17: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 4.78 → 15.65\n",
      "Step 18: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 30.57 → 47.07\n",
      "Step 19: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 71.74 → 80.02\n",
      "Step 20: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.22 → 99.61\n",
      "\n",
      "Episode 61\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.44 → -5.37\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.79 → -4.85\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.35 → -4.52\n",
      "Step 4: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.11 → -4.53\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -4.38 → -4.53\n",
      "Step 6: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploiting, Q -4.09 → -4.58\n",
      "Step 7: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.52 → -4.62\n",
      "Step 8: State (2, 1), Action UP, Reward -1, Next (1, 1), Mode Exploiting, Q -4.14 → -4.79\n",
      "Step 9: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -4.95 → -5.48\n",
      "Step 10: State (0, 1), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -5.57 → -5.70\n",
      "Step 11: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.37 → -5.37\n",
      "Step 12: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.85 → -4.97\n",
      "Step 13: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -4.53 → -4.61\n",
      "Step 14: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.09 → -4.22\n",
      "Step 15: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.73 → -3.79\n",
      "Step 16: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -3.16 → -3.39\n",
      "Step 17: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -2.91 → -3.15\n",
      "Step 18: State (6, 1), Action DOWN, Reward -1, Next (7, 1), Mode Exploiting, Q -2.66 → -2.93\n",
      "Step 19: State (7, 1), Action LEFT, Reward -1, Next (7, 0), Mode Exploring, Q -2.45 → -2.89\n",
      "Step 20: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.58 → -2.95\n",
      "Step 21: State (7, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.95 → -3.15\n",
      "Step 22: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploring, Q -2.60 → -1.44\n",
      "Step 23: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploring, Q 0.80 → 1.72\n",
      "Step 24: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 4.04 → 8.56\n",
      "Step 25: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 15.65 → 28.50\n",
      "Step 26: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 47.07 → 59.04\n",
      "Step 27: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploring, Q 80.02 → 84.33\n",
      "Step 28: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.61 → 99.80\n",
      "\n",
      "Episode 62\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.37 → -5.42\n",
      "Step 2: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.96 → -5.25\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.05 → -5.05\n",
      "Step 4: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -4.51 → -4.78\n",
      "Step 5: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -4.51 → -4.74\n",
      "Step 6: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploring, Q -4.41 → -4.47\n",
      "Step 7: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -3.92 → -4.47\n",
      "Step 8: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploring, Q -4.46 → -4.64\n",
      "Step 9: State (1, 3), Action LEFT, Reward -1, Next (1, 2), Mode Exploiting, Q -4.25 → -4.72\n",
      "Step 10: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploiting, Q -4.66 → -5.29\n",
      "Step 11: State (1, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -5.48 → -5.65\n",
      "Step 12: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -5.36 → -5.42\n",
      "Step 13: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.98 → -5.10\n",
      "Step 14: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -4.68 → -5.00\n",
      "Step 15: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploring, Q -4.78 → -5.02\n",
      "Step 16: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -4.74 → -4.79\n",
      "Step 17: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.27 → -4.79\n",
      "Step 18: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -4.78 → -5.04\n",
      "Step 19: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -5.04 → -5.18\n",
      "Step 20: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -4.79 → -4.91\n",
      "Step 21: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -4.47 → -4.75\n",
      "Step 22: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploiting, Q -4.47 → -4.82\n",
      "Step 23: State (2, 3), Action UP, Reward -1, Next (1, 3), Mode Exploring, Q -4.64 → -4.91\n",
      "Step 24: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -4.64 → -4.19\n",
      "Step 25: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -3.05 → -3.16\n",
      "Step 26: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploiting, Q -2.53 → -2.81\n",
      "Step 27: State (1, 6), Action LEFT, Reward -1, Next (1, 5), Mode Exploiting, Q -2.32 → -2.89\n",
      "Step 28: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -2.74 → -2.77\n",
      "Step 29: State (0, 5), Action DOWN, Reward -1, Next (1, 5), Mode Exploiting, Q -2.00 → -2.75\n",
      "Step 30: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -2.77 → -2.79\n",
      "Step 31: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploiting, Q -2.02 → -2.49\n",
      "Step 32: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -2.17 → -2.60\n",
      "Step 33: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploring, Q -2.26 → -2.58\n",
      "Step 34: State (1, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -2.12 → -2.48\n",
      "Step 35: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -2.04 → -2.43\n",
      "Step 36: State (0, 7), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -2.43 → -2.69\n",
      "Step 37: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploiting, Q -2.16 → -2.55\n",
      "Step 38: State (0, 7), Action UP, Reward -1, Next (0, 7), Mode Exploring, Q -2.55 → -2.78\n",
      "Step 39: State (0, 7), Action LEFT, Reward -1, Next (0, 6), Mode Exploiting, Q -2.22 → -2.71\n",
      "Step 40: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -2.44 → -2.81\n",
      "Step 41: State (0, 6), Action UP, Reward -1, Next (0, 6), Mode Exploiting, Q -2.81 → -3.02\n",
      "Step 42: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploiting, Q -2.48 → -2.83\n",
      "Step 43: State (1, 6), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -2.42 → -2.72\n",
      "Step 44: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -2.25 → -2.64\n",
      "Step 45: State (1, 7), Action RIGHT, Reward -1, Next (1, 7), Mode Exploiting, Q -2.64 → -2.83\n",
      "Step 46: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -2.25 → -0.83\n",
      "Step 47: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q 1.76 → 9.22\n",
      "Step 48: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 19.65 → 31.57\n",
      "Step 49: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 49.43 → 63.17\n",
      "Step 50: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 86.58 → 87.79\n",
      "Step 51: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 63\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -5.42 → -5.44\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -4.97 → -5.06\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -4.62 → -4.69\n",
      "Step 4: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.17 → -4.29\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.79 → -3.97\n",
      "Step 6: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -3.51 → -3.42\n",
      "Step 7: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -2.58 → -3.02\n",
      "Step 8: State (3, 4), Action UP, Reward -1, Next (2, 4), Mode Exploring, Q -2.72 → -3.27\n",
      "Step 9: State (2, 4), Action RIGHT, Reward -1, Next (2, 5), Mode Exploring, Q -3.14 → -3.23\n",
      "Step 10: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q -2.58 → 4.20\n",
      "Step 11: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q 13.32 → 25.74\n",
      "Step 12: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 43.51 → 49.65\n",
      "Step 13: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 63.10 → 64.26\n",
      "Step 14: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploring, Q 73.79 → 75.90\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 87.79 → 88.39\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 64\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.44 → -5.50\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.06 → -5.08\n",
      "Step 3: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.56 → -4.83\n",
      "Step 4: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.83 → -4.99\n",
      "Step 5: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -4.61 → -4.70\n",
      "Step 6: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -4.21 → -4.50\n",
      "Step 7: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -4.50 → -4.65\n",
      "Step 8: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.22 → -4.32\n",
      "Step 9: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -3.79 → -4.00\n",
      "Step 10: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -3.58 → -3.90\n",
      "Step 11: State (5, 0), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -3.90 → -3.94\n",
      "Step 12: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -3.33 → -3.54\n",
      "Step 13: State (6, 0), Action RIGHT, Reward -1, Next (6, 1), Mode Exploiting, Q -3.06 → -3.26\n",
      "Step 14: State (6, 1), Action RIGHT, Reward -1, Next (6, 2), Mode Exploiting, Q -2.73 → -3.00\n",
      "Step 15: State (6, 2), Action RIGHT, Reward -1, Next (6, 3), Mode Exploiting, Q -2.51 → -2.64\n",
      "Step 16: State (6, 3), Action RIGHT, Reward -1, Next (6, 4), Mode Exploiting, Q -1.97 → 6.32\n",
      "Step 17: State (6, 4), Action DOWN, Reward -1, Next (7, 4), Mode Exploiting, Q 17.34 → 34.74\n",
      "Step 18: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 59.04 → 28.68\n",
      "Step 19: State (7, 5), Action DOWN, Reward -1, Next (7, 5), Mode Exploring, Q -0.75 → 37.08\n",
      "Step 20: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 84.33 → 86.58\n",
      "Step 21: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.80 → 99.90\n",
      "\n",
      "Episode 65\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.50 → -5.53\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.07 → -5.32\n",
      "Step 3: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.32 → -5.45\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.08 → -5.15\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.69 → -4.77\n",
      "Step 6: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.29 → -4.35\n",
      "Step 7: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -3.79 → -4.34\n",
      "Step 8: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.32 → -4.41\n",
      "Step 9: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploiting, Q -3.89 → -4.43\n",
      "Step 10: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.41 → -4.51\n",
      "Step 11: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -4.00 → -4.11\n",
      "Step 12: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploring, Q -3.57 → -4.28\n",
      "Step 13: State (4, 0), Action UP, Reward -1, Next (3, 0), Mode Exploring, Q -4.43 → -4.78\n",
      "Step 14: State (3, 0), Action UP, Reward -1, Next (2, 0), Mode Exploring, Q -4.58 → -4.91\n",
      "Step 15: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -4.70 → -4.88\n",
      "Step 16: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.51 → -4.60\n",
      "Step 17: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -4.11 → -4.48\n",
      "Step 18: State (5, 0), Action UP, Reward -1, Next (4, 0), Mode Exploring, Q -4.28 → -4.66\n",
      "Step 19: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -4.48 → -4.27\n",
      "Step 20: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -3.39 → -3.54\n",
      "Step 21: State (5, 1), Action LEFT, Reward -1, Next (5, 0), Mode Exploring, Q -2.99 → -3.59\n",
      "Step 22: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -3.54 → -3.66\n",
      "Step 23: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -3.09 → -2.69\n",
      "Step 24: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -1.44 → -0.45\n",
      "Step 25: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q 1.72 → 4.21\n",
      "Step 26: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 8.56 → 16.61\n",
      "Step 27: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 28.50 → 26.66\n",
      "Step 28: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 28.68 → 52.80\n",
      "Step 29: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 86.58 → 87.75\n",
      "Step 30: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.90 → 99.95\n",
      "\n",
      "Episode 66\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.53 → -5.58\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.15 → -5.22\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.77 → -4.84\n",
      "Step 4: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.35 → -4.46\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.97 → -4.03\n",
      "Step 6: State (3, 2), Action RIGHT, Reward -1, Next (3, 3), Mode Exploiting, Q -3.42 → -3.81\n",
      "Step 7: State (3, 3), Action LEFT, Reward -1, Next (3, 2), Mode Exploring, Q -3.56 → -3.88\n",
      "Step 8: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploring, Q -3.56 → -3.37\n",
      "Step 9: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploring, Q -2.43 → -0.96\n",
      "Step 10: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q 1.67 → 6.57\n",
      "Step 11: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 13.85 → 28.77\n",
      "Step 12: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploring, Q 49.65 → 53.24\n",
      "Step 13: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 64.26 → 65.78\n",
      "Step 14: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 75.90 → 77.23\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 88.39 → 88.70\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 67\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.58 → -5.64\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.22 → -5.29\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -4.84 → -4.93\n",
      "Step 4: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.46 → -4.54\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -4.03 → -4.03\n",
      "Step 6: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -3.37 → -2.62\n",
      "Step 7: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q -0.96 → 1.97\n",
      "Step 8: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q 6.57 → 15.73\n",
      "Step 9: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 28.77 → 37.84\n",
      "Step 10: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 53.24 → 55.72\n",
      "Step 11: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 65.78 → 67.14\n",
      "Step 12: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 77.23 → 78.03\n",
      "Step 13: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 88.70 → 43.85\n",
      "Step 14: State (6, 7), Action LEFT, Reward -10, Next (6, 6), Mode Exploring, Q 0.00 → -5.00\n",
      "\n",
      "Episode 68\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.59 → -5.59\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -5.10 → -5.26\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -4.91 → -5.09\n",
      "Step 4: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -4.75 → -5.04\n",
      "Step 5: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -4.82 → -4.50\n",
      "Step 6: State (2, 3), Action DOWN, Reward -1, Next (3, 3), Mode Exploiting, Q -3.54 → -3.63\n",
      "Step 7: State (3, 3), Action RIGHT, Reward -1, Next (3, 4), Mode Exploiting, Q -3.02 → -2.17\n",
      "Step 8: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q -0.37 → 16.35\n",
      "Step 9: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 37.84 → 43.50\n",
      "Step 10: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 55.72 → 26.67\n",
      "Step 11: State (5, 5), Action UP, Reward -1, Next (4, 5), Mode Exploring, Q -1.55 → 10.73\n",
      "Step 12: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 26.67 → 43.05\n",
      "Step 13: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 67.14 → 68.18\n",
      "Step 14: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 78.03 → 58.25\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 43.85 → 66.42\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 69\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.59 → -5.63\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -5.19 → -5.37\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.05 → -5.41\n",
      "Step 4: State (1, 2), Action LEFT, Reward -1, Next (1, 1), Mode Exploring, Q -5.29 → -5.44\n",
      "Step 5: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.11 → -5.42\n",
      "Step 6: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploiting, Q -5.25 → -5.56\n",
      "Step 7: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.41 → -5.31\n",
      "Step 8: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.67 → -4.86\n",
      "Step 9: State (1, 3), Action DOWN, Reward -1, Next (2, 3), Mode Exploring, Q -4.50 → -4.35\n",
      "Step 10: State (2, 3), Action RIGHT, Reward -1, Next (2, 4), Mode Exploiting, Q -3.55 → -3.62\n",
      "Step 11: State (2, 4), Action UP, Reward -1, Next (1, 4), Mode Exploiting, Q -2.98 → -3.41\n",
      "Step 12: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploring, Q -3.16 → -3.34\n",
      "Step 13: State (1, 5), Action UP, Reward -1, Next (0, 5), Mode Exploiting, Q -2.79 → -3.02\n",
      "Step 14: State (0, 5), Action RIGHT, Reward -1, Next (0, 6), Mode Exploiting, Q -2.49 → -2.92\n",
      "Step 15: State (0, 6), Action RIGHT, Reward -1, Next (0, 7), Mode Exploiting, Q -2.60 → -2.96\n",
      "Step 16: State (0, 7), Action DOWN, Reward -1, Next (1, 7), Mode Exploiting, Q -2.58 → -2.17\n",
      "Step 17: State (1, 7), Action DOWN, Reward -1, Next (2, 7), Mode Exploiting, Q -0.83 → 3.23\n",
      "Step 18: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q 9.22 → 18.32\n",
      "Step 19: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 31.57 → 43.71\n",
      "Step 20: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 63.17 → 60.98\n",
      "Step 21: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 66.42 → 77.71\n",
      "Step 22: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 70\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.63 → -5.68\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -5.26 → -5.36\n",
      "Step 3: State (0, 2), Action LEFT, Reward -1, Next (0, 1), Mode Exploiting, Q -4.95 → -5.39\n",
      "Step 4: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -5.36 → -5.43\n",
      "Step 5: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploiting, Q -5.00 → -5.19\n",
      "Step 6: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.86 → -4.82\n",
      "Step 7: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -4.19 → -4.10\n",
      "Step 8: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -3.34 → -3.43\n",
      "Step 9: State (1, 5), Action RIGHT, Reward -1, Next (1, 6), Mode Exploiting, Q -2.81 → -3.02\n",
      "Step 10: State (1, 6), Action UP, Reward -1, Next (0, 6), Mode Exploring, Q -2.48 → -3.01\n",
      "Step 11: State (0, 6), Action DOWN, Reward -1, Next (1, 6), Mode Exploiting, Q -2.83 → -3.11\n",
      "Step 12: State (1, 6), Action DOWN, Reward -1, Next (2, 6), Mode Exploiting, Q -2.65 → -2.89\n",
      "Step 13: State (2, 6), Action RIGHT, Reward -1, Next (2, 7), Mode Exploiting, Q -2.36 → 6.56\n",
      "Step 14: State (2, 7), Action DOWN, Reward -1, Next (3, 7), Mode Exploiting, Q 18.32 → 28.33\n",
      "Step 15: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 43.71 → 48.80\n",
      "Step 16: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 60.98 → 64.96\n",
      "Step 17: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 77.71 → 83.36\n",
      "Step 18: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 71\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.64 → -5.70\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.29 → -5.36\n",
      "Step 3: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploring, Q -4.93 → -5.00\n",
      "Step 4: State (2, 1), Action LEFT, Reward -1, Next (2, 0), Mode Exploiting, Q -4.53 → -5.01\n",
      "Step 5: State (2, 0), Action LEFT, Reward -1, Next (2, 0), Mode Exploring, Q -4.99 → -5.19\n",
      "Step 6: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -4.88 → -5.00\n",
      "Step 7: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -4.58 → -4.74\n",
      "Step 8: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q -4.34 → -4.74\n",
      "Step 9: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.60 → -4.72\n",
      "Step 10: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -4.27 → -4.23\n",
      "Step 11: State (5, 0), Action RIGHT, Reward -1, Next (5, 1), Mode Exploiting, Q -3.54 → -3.69\n",
      "Step 12: State (5, 1), Action DOWN, Reward -1, Next (6, 1), Mode Exploiting, Q -3.15 → -3.33\n",
      "Step 13: State (6, 1), Action LEFT, Reward -1, Next (6, 0), Mode Exploiting, Q -2.79 → -3.11\n",
      "Step 14: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.69 → -2.05\n",
      "Step 15: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q -0.45 → 1.17\n",
      "Step 16: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q 4.21 → 0.56\n",
      "Step 17: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploring, Q -2.32 → -1.41\n",
      "Step 18: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploring, Q 0.56 → -0.85\n",
      "Step 19: State (7, 2), Action LEFT, Reward -1, Next (7, 1), Mode Exploring, Q -1.41 → -1.59\n",
      "Step 20: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q -0.85 → 6.55\n",
      "Step 21: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 16.61 → 19.80\n",
      "Step 22: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 26.66 → 36.59\n",
      "Step 23: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 52.80 → 65.39\n",
      "Step 24: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 87.75 → 88.35\n",
      "Step 25: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.95 → 99.98\n",
      "\n",
      "Episode 72\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.68 → -5.76\n",
      "Step 2: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -5.37 → -5.57\n",
      "Step 3: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.31 → -5.32\n",
      "Step 4: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.82 → -4.75\n",
      "Step 5: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -4.10 → -4.09\n",
      "Step 6: State (1, 4), Action DOWN, Reward -1, Next (2, 4), Mode Exploiting, Q -3.42 → -3.65\n",
      "Step 7: State (2, 4), Action DOWN, Reward -1, Next (3, 4), Mode Exploiting, Q -3.21 → 5.25\n",
      "Step 8: State (3, 4), Action DOWN, Reward -1, Next (4, 4), Mode Exploiting, Q 16.35 → 27.25\n",
      "Step 9: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 43.50 → 40.62\n",
      "Step 10: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 43.05 → 51.71\n",
      "Step 11: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 68.18 → 59.80\n",
      "Step 12: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 58.25 → 28.11\n",
      "Step 13: State (5, 7), Action UP, Reward -1, Next (4, 7), Mode Exploring, Q -1.14 → 28.16\n",
      "Step 14: State (4, 7), Action DOWN, Reward -1, Next (5, 7), Mode Exploiting, Q 64.96 → 69.49\n",
      "Step 15: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 83.36 → 86.18\n",
      "Step 16: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 73\n",
      "Step 1: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -5.84 → -6.05\n",
      "Step 2: State (0, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -6.05 → -6.09\n",
      "Step 3: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.70 → -5.85\n",
      "Step 4: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploring, Q -5.56 → -5.67\n",
      "Step 5: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.32 → -5.42\n",
      "Step 6: State (1, 2), Action UP, Reward -1, Next (0, 2), Mode Exploring, Q -5.02 → -5.30\n",
      "Step 7: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -5.09 → -5.20\n",
      "Step 8: State (0, 3), Action LEFT, Reward -1, Next (0, 2), Mode Exploiting, Q -4.79 → -5.22\n",
      "Step 9: State (0, 2), Action UP, Reward -1, Next (0, 2), Mode Exploiting, Q -5.18 → -5.42\n",
      "Step 10: State (0, 2), Action DOWN, Reward -1, Next (1, 2), Mode Exploring, Q -5.19 → -5.23\n",
      "Step 11: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploring, Q -4.75 → -4.72\n",
      "Step 12: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -4.09 → -4.09\n",
      "Step 13: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -3.43 → -3.55\n",
      "Step 14: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -2.97 → -0.09\n",
      "Step 15: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q 4.20 → 13.18\n",
      "Step 16: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q 25.74 → 35.64\n",
      "Step 17: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 51.71 → 52.26\n",
      "Step 18: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 59.80 → 42.05\n",
      "Step 19: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 28.11 → 52.33\n",
      "Step 20: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 86.18 → 87.59\n",
      "Step 21: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 74\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.76 → -5.82\n",
      "Step 2: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploiting, Q -5.42 → -5.65\n",
      "Step 3: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploring, Q -5.43 → -5.55\n",
      "Step 4: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploiting, Q -5.20 → -5.37\n",
      "Step 5: State (0, 3), Action DOWN, Reward -1, Next (1, 3), Mode Exploiting, Q -5.04 → -4.86\n",
      "Step 6: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploiting, Q -4.09 → -5.92\n",
      "Step 7: State (1, 4), Action UP, Reward -10, Next (0, 4), Mode Exploring, Q -7.50 → -8.75\n",
      "\n",
      "Episode 75\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.82 → -5.91\n",
      "Step 2: State (0, 1), Action RIGHT, Reward -1, Next (0, 2), Mode Exploiting, Q -5.55 → -5.69\n",
      "Step 3: State (0, 2), Action RIGHT, Reward -1, Next (0, 3), Mode Exploring, Q -5.37 → -7.40\n",
      "Step 4: State (0, 3), Action RIGHT, Reward -10, Next (0, 4), Mode Exploring, Q -9.38 → -9.69\n",
      "\n",
      "Episode 76\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.85 → -5.84\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.36 → -5.42\n",
      "Step 3: State (2, 0), Action UP, Reward -1, Next (1, 0), Mode Exploiting, Q -4.97 → -5.54\n",
      "Step 4: State (1, 0), Action RIGHT, Reward -1, Next (1, 1), Mode Exploring, Q -5.67 → -5.77\n",
      "Step 5: State (1, 1), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.42 → -5.73\n",
      "Step 6: State (1, 0), Action UP, Reward -1, Next (0, 0), Mode Exploring, Q -5.59 → -5.93\n",
      "Step 7: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -5.84 → -5.86\n",
      "Step 8: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.42 → -5.46\n",
      "Step 9: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploiting, Q -5.00 → -5.09\n",
      "Step 10: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -4.65 → -4.92\n",
      "Step 11: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploiting, Q -4.92 → -5.17\n",
      "Step 12: State (3, 0), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q -5.17 → -5.21\n",
      "Step 13: State (3, 0), Action DOWN, Reward -1, Next (4, 0), Mode Exploiting, Q -4.72 → -4.76\n",
      "Step 14: State (4, 0), Action DOWN, Reward -1, Next (5, 0), Mode Exploiting, Q -4.23 → -4.26\n",
      "Step 15: State (5, 0), Action DOWN, Reward -1, Next (6, 0), Mode Exploiting, Q -3.66 → -3.25\n",
      "Step 16: State (6, 0), Action DOWN, Reward -1, Next (7, 0), Mode Exploiting, Q -2.05 → -1.00\n",
      "Step 17: State (7, 0), Action RIGHT, Reward -1, Next (7, 1), Mode Exploiting, Q 1.17 → 3.03\n",
      "Step 18: State (7, 1), Action RIGHT, Reward -1, Next (7, 2), Mode Exploiting, Q 6.55 → 11.68\n",
      "Step 19: State (7, 2), Action RIGHT, Reward -1, Next (7, 3), Mode Exploiting, Q 19.80 → 25.87\n",
      "Step 20: State (7, 3), Action RIGHT, Reward -1, Next (7, 4), Mode Exploiting, Q 36.59 → 47.22\n",
      "Step 21: State (7, 4), Action RIGHT, Reward -1, Next (7, 5), Mode Exploiting, Q 65.39 → 71.95\n",
      "Step 22: State (7, 5), Action RIGHT, Reward -1, Next (7, 6), Mode Exploiting, Q 88.35 → 88.66\n",
      "Step 23: State (7, 6), Action RIGHT, Reward 100, Next (7, 7), Mode Exploiting, Q 99.98 → 99.99\n",
      "\n",
      "Episode 77\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.86 → -5.88\n",
      "Step 2: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.45 → -5.67\n",
      "Step 3: State (1, 0), Action LEFT, Reward -1, Next (1, 0), Mode Exploiting, Q -5.67 → -5.79\n",
      "Step 4: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.46 → -5.48\n",
      "Step 5: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -5.00 → -5.05\n",
      "Step 6: State (2, 1), Action DOWN, Reward -1, Next (3, 1), Mode Exploiting, Q -4.54 → -4.90\n",
      "Step 7: State (3, 1), Action LEFT, Reward -1, Next (3, 0), Mode Exploring, Q -4.74 → -5.01\n",
      "Step 8: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -4.74 → -4.69\n",
      "Step 9: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -4.03 → -3.69\n",
      "Step 10: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -2.62 → -0.92\n",
      "Step 11: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q 1.97 → 7.57\n",
      "Step 12: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q 15.73 → 25.64\n",
      "Step 13: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 40.62 → 43.33\n",
      "Step 14: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 52.26 → 44.55\n",
      "Step 15: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 42.05 → 44.08\n",
      "Step 16: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 52.33 → 65.08\n",
      "Step 17: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 87.59 → 88.29\n",
      "Step 18: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 78\n",
      "Step 1: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -5.87 → -6.08\n",
      "Step 2: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploiting, Q -6.08 → -6.27\n",
      "Step 3: State (0, 0), Action LEFT, Reward -1, Next (0, 0), Mode Exploring, Q -6.27 → -6.28\n",
      "Step 4: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploring, Q -5.88 → -5.91\n",
      "Step 5: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.48 → -5.51\n",
      "Step 6: State (2, 0), Action RIGHT, Reward -1, Next (2, 1), Mode Exploiting, Q -5.05 → -6.96\n",
      "Step 7: State (2, 1), Action RIGHT, Reward -10, Next (2, 2), Mode Exploring, Q -8.75 → -9.38\n",
      "\n",
      "Episode 79\n",
      "Step 1: State (0, 0), Action DOWN, Reward -1, Next (1, 0), Mode Exploiting, Q -5.91 → -5.93\n",
      "Step 2: State (1, 0), Action DOWN, Reward -1, Next (2, 0), Mode Exploiting, Q -5.51 → -5.55\n",
      "Step 3: State (2, 0), Action DOWN, Reward -1, Next (3, 0), Mode Exploring, Q -5.09 → -5.16\n",
      "Step 4: State (3, 0), Action RIGHT, Reward -1, Next (3, 1), Mode Exploiting, Q -4.69 → -4.50\n",
      "Step 5: State (3, 1), Action RIGHT, Reward -1, Next (3, 2), Mode Exploiting, Q -3.69 → -2.76\n",
      "Step 6: State (3, 2), Action DOWN, Reward -1, Next (4, 2), Mode Exploiting, Q -0.92 → 2.44\n",
      "Step 7: State (4, 2), Action RIGHT, Reward -1, Next (4, 3), Mode Exploiting, Q 7.57 → 14.82\n",
      "Step 8: State (4, 3), Action RIGHT, Reward -1, Next (4, 4), Mode Exploiting, Q 25.64 → 31.82\n",
      "Step 9: State (4, 4), Action RIGHT, Reward -1, Next (4, 5), Mode Exploiting, Q 43.33 → 41.21\n",
      "Step 10: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 44.55 → 41.61\n",
      "Step 11: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 44.08 → 50.82\n",
      "Step 12: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 65.08 → 71.77\n",
      "Step 13: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 88.29 → 88.65\n",
      "Step 14: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n",
      "\n",
      "Episode 80\n",
      "Step 1: State (0, 0), Action RIGHT, Reward -1, Next (0, 1), Mode Exploiting, Q -5.91 → -6.00\n",
      "Step 2: State (0, 1), Action UP, Reward -1, Next (0, 1), Mode Exploring, Q -5.65 → -5.83\n",
      "Step 3: State (0, 1), Action DOWN, Reward -1, Next (1, 1), Mode Exploiting, Q -5.57 → -5.73\n",
      "Step 4: State (1, 1), Action RIGHT, Reward -1, Next (1, 2), Mode Exploiting, Q -5.42 → -5.33\n",
      "Step 5: State (1, 2), Action RIGHT, Reward -1, Next (1, 3), Mode Exploiting, Q -4.72 → -5.52\n",
      "Step 6: State (1, 3), Action RIGHT, Reward -1, Next (1, 4), Mode Exploring, Q -5.92 → -5.06\n",
      "Step 7: State (1, 4), Action RIGHT, Reward -1, Next (1, 5), Mode Exploiting, Q -3.55 → -2.32\n",
      "Step 8: State (1, 5), Action DOWN, Reward -1, Next (2, 5), Mode Exploiting, Q -0.09 → 5.39\n",
      "Step 9: State (2, 5), Action DOWN, Reward -1, Next (3, 5), Mode Exploiting, Q 13.18 → 22.13\n",
      "Step 10: State (3, 5), Action DOWN, Reward -1, Next (4, 5), Mode Exploiting, Q 35.64 → 36.04\n",
      "Step 11: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 41.61 → 25.13\n",
      "Step 12: State (5, 5), Action UP, Reward -1, Next (4, 5), Mode Exploring, Q 10.73 → 3.89\n",
      "Step 13: State (4, 5), Action RIGHT, Reward -1, Next (4, 6), Mode Exploring, Q -2.16 → 2.39\n",
      "Step 14: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q 8.83 → 15.22\n",
      "Step 15: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 25.13 → 34.94\n",
      "Step 16: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 50.82 → 24.42\n",
      "Step 17: State (5, 6), Action UP, Reward -1, Next (4, 6), Mode Exploring, Q -1.09 → 5.81\n",
      "Step 18: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q 15.22 → 22.83\n",
      "Step 19: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploring, Q 34.94 → 27.96\n",
      "Step 20: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 24.42 → 14.32\n",
      "Step 21: State (5, 6), Action UP, Reward -1, Next (4, 6), Mode Exploring, Q 5.81 → 1.67\n",
      "Step 22: State (4, 6), Action UP, Reward -1, Next (3, 6), Mode Exploring, Q -1.63 → -0.63\n",
      "Step 23: State (3, 6), Action RIGHT, Reward -1, Next (3, 7), Mode Exploiting, Q 1.52 → 22.22\n",
      "Step 24: State (3, 7), Action DOWN, Reward -1, Next (4, 7), Mode Exploiting, Q 48.80 → 23.23\n",
      "Step 25: State (4, 7), Action LEFT, Reward -1, Next (4, 6), Mode Exploring, Q -1.48 → 9.03\n",
      "Step 26: State (4, 6), Action LEFT, Reward -1, Next (4, 5), Mode Exploiting, Q 22.83 → 23.50\n",
      "Step 27: State (4, 5), Action DOWN, Reward -1, Next (5, 5), Mode Exploiting, Q 27.96 → 19.93\n",
      "Step 28: State (5, 5), Action RIGHT, Reward -1, Next (5, 6), Mode Exploiting, Q 14.32 → 38.96\n",
      "Step 29: State (5, 6), Action RIGHT, Reward -1, Next (5, 7), Mode Exploiting, Q 71.77 → 75.28\n",
      "Step 30: State (5, 7), Action DOWN, Reward -1, Next (6, 7), Mode Exploiting, Q 88.65 → 43.49\n",
      "Step 31: State (6, 7), Action RIGHT, Reward -1, Next (6, 7), Mode Exploring, Q -0.75 → 44.12\n",
      "Step 32: State (6, 7), Action DOWN, Reward 100, Next (7, 7), Mode Exploiting, Q 100.00 → 100.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def step(state, action):\n",
    "    x, y = state\n",
    "\n",
    "    if action == 0 and x > 0:\n",
    "        x -= 1\n",
    "    elif action == 1 and x < GridSize - 1:\n",
    "        x += 1\n",
    "    elif action == 2 and y > 0:\n",
    "        y -= 1\n",
    "    elif action == 3 and y < GridSize - 1:\n",
    "        y += 1\n",
    "\n",
    "    next_state = (x, y)\n",
    "\n",
    "    if next_state == Goal:\n",
    "        reward = 100\n",
    "    elif next_state in Traps:\n",
    "        reward = -10\n",
    "    else:\n",
    "        reward = -1\n",
    "\n",
    "    return next_state, reward\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def draw_grid(state=None, path=None, final=False):\n",
    "    grid = np.ones((GridSize, GridSize, 3))\n",
    "\n",
    "    for i in range(GridSize):\n",
    "        for j in range(GridSize):\n",
    "            if (i, j) == Goal:\n",
    "                grid[i, j] = [0, 1, 0]\n",
    "            elif (i, j) in Traps:\n",
    "                grid[i, j] = [1, 0, 0]\n",
    "            elif path and (i, j) in path:\n",
    "                grid[i, j] = [1, 1, 0]\n",
    "            elif state is not None and (i, j) == state:\n",
    "                grid[i, j] = [0, 0, 1]\n",
    "\n",
    "    ax.clear()\n",
    "    ax.imshow(grid)\n",
    "    ax.set_xticks(np.arange(-0.5, GridSize, 1))\n",
    "    ax.set_yticks(np.arange(-0.5, GridSize, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    if not final:\n",
    "        time.sleep(Delay)\n",
    "\n",
    "\n",
    "def choose_action(state):\n",
    "    if random.random() < Epsilon:\n",
    "        return random.randint(0, 3), \"Exploring\"\n",
    "    else:\n",
    "        if np.all(Q[state[0], state[1]] == 0):\n",
    "            return random.randint(0, 3), \"Exploring\"\n",
    "        else:\n",
    "            return np.argmax(Q[state[0], state[1]]), \"Exploiting\"\n",
    "\n",
    "\n",
    "for ep in range(Episodes): # SARSA training\n",
    "    print(f\"\\nEpisode {ep + 1}\")\n",
    "    state = (0, 0)\n",
    "    action, mode = choose_action(state)\n",
    "    step_count = 0\n",
    "\n",
    "    while state != Goal and state not in Traps:\n",
    "        step_count += 1\n",
    "\n",
    "        next_state, reward = step(state, action)\n",
    "        next_action, next_mode = choose_action(next_state)\n",
    "\n",
    "        old_q = Q[state[0], state[1], action]\n",
    "\n",
    "        Q[state[0], state[1], action] += Alpha * (\n",
    "            reward + Gamma * Q[next_state[0], next_state[1], next_action]\n",
    "            - Q[state[0], state[1], action]\n",
    "        )\n",
    "\n",
    "        draw_grid(next_state)\n",
    "\n",
    "        print(\n",
    "            f\"Step {step_count}: State {state}, Action {ActionsList[action]}, \"\n",
    "            f\"Reward {reward}, Next {next_state}, Mode {mode}, \"\n",
    "            f\"Q {old_q:.2f} → {Q[state[0], state[1], action]:.2f}\"\n",
    "        )\n",
    "\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "        mode = next_mode\n",
    "\n",
    "\n",
    "state = (0, 0) # Printing Learned Path, optimal one \n",
    "optimal_path = [state]\n",
    "\n",
    "while state != Goal:\n",
    "    action = np.argmax(Q[state[0], state[1]])\n",
    "\n",
    "    if action == 0 and state[0] > 0:\n",
    "        state = (state[0] - 1, state[1])\n",
    "    elif action == 1 and state[0] < GridSize - 1:\n",
    "        state = (state[0] + 1, state[1])\n",
    "    elif action == 2 and state[1] > 0:\n",
    "        state = (state[0], state[1] - 1)\n",
    "    elif action == 3 and state[1] < GridSize - 1:\n",
    "        state = (state[0], state[1] + 1)\n",
    "\n",
    "    if state in optimal_path:\n",
    "        break\n",
    "\n",
    "    optimal_path.append(state)\n",
    "\n",
    "\n",
    "draw_grid(state=None, path=optimal_path, final=True)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
